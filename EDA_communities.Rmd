---
title: 'Data ETL: Communities'
author: "Florian Mayer and Milly Piggott, DBCA"
date: "`r Sys.time()`"
always_allow_html: yes
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    fig_width: 10
    fig_height: 6
    code_folding: hide
    theme: lumen
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = TRUE)
source("helpers.R")
default_date <- lubridate::parse_date_time(
  "1900-01-01 00:00:00", 
  orders = "ymd HMS", 
  tz = "Australia/Perth"
)
```

# Context
This workbook summarises the legacy data migration and QA for the Threatened
Ecological Communities database (TEC).

![](https://data.dbca.wa.gov.au/dataset/79e90d7b-33a3-4aa0-8634-8a12033eb21d/resource/98588a4e-b3af-452b-bbf4-f63ca7697752/download/tsc-progress.jpg){width="100%"}

By default, all code blocks are collapsed to provide better readability to the
non-technical audience. Feel free to expand the code blocks to view the process.

The code for all SCB workbooks is under version control at
[github](https://github.com/dbca-wa/scarab-scripts).

# Legacy Data (TFL)

Data from the Threatened Ecological Communities Database (TEC) is downloaded from the 
[TEC dataset](https://data.dbca.wa.gov.au/dataset/threatened-ecological-communities-database)
on the DBCA data catalogue, then extracted and transformed.

## Communities

```{r get_tec, message=FALSE}
# Cached data from TFL database on CKAN - delete to force refresh
tec_file <- here::here("data/tec.Rdata")

if (file.exists(tec_file)) {
  load(tec_file)
} else {
  tec <- dl_mdbzip("598b1e70-5707-4dbc-a665-1189e1524ebe")
  tec_file <- here::here("data", "tec.Rdata")
save(tec, file=tec_file)
}

tec_bdy <- geojsonsf::geojson_sf("data/tec_boundaries.geojson")
tec_site <- geojsonsf::geojson_sf("data/tec_sites.geojson")
# tec_buf <- geojsonsf::geojson_sf("data/tec_buffers.geojson")
# tec_app <- dl_mdbzip("27d9b026-6933-4516-acf6-41edc6134adb")

snapshot_last_updated <- "598b1e70-5707-4dbc-a665-1189e1524ebe" %>%
  ckanr::resource_show() %>%
  magrittr::extract2("last_modified") %>%
  lubridate::as_datetime() %>%
  lubridate::with_tz("Australia/Perth")

# Cached data from TSC - delete to force refresh
# datafile_tsc_comm <- here::here("data", "etl_comm_tsc.Rda")
tsc_cl_community_datafile <- here::here("data/tsc_cl_community.RData")
tsc_occ_community_datafile <- here::here("data/tsc_tae_community.RData")


former_range <- tec$FORMER_RANGES %>%
  dplyr::transmute(
    former_range_code = FORMER.RANGE %>% as.character(),
    former_range = FORMER.RANGE.DESC %>% as.character()
  )
# make_coldef(former_range)
readr::write_csv(former_range, path = here::here("data", "tec_former_range.csv"))

range_decline <- tec$RANGE_DECLINE %>%
  dplyr::transmute(
    range_decline_id = RANGE.DECLINE %>% as.integer(),
    range_decline = RANGE.DECLINE.DESC %>% as.character()
  )
# make_coldef(range_decline)
readr::write_csv(range_decline, path = here::here("data", "tec_range_decline.csv"))

occ_decline <- tec$OCCURRENCES_DECLINE %>%
  dplyr::transmute(
    occ_decline_id = OCC.DECLINE %>% as.integer(),
    occ_decline = OCC.DECLINE.DESC %>% as.character()
  )
# make_coldef(occ_decline)
readr::write_csv(occ_decline, path = here::here("data", "tec_occ_decline.csv"))

status <- tec$STATUS %>%
  dplyr::transmute(
    status_code = STATUS.CODE %>% as.character(),
    status = STATUS.DESC %>% as.character()
  )
# status %>% make_coldef()
# unique(status$status_code) # "BELIEVED"   "IDENTIFIED" - where used?
readr::write_csv(status, path = here::here("data", "tec_status.csv"))

communities <- tec$COMMUNITIES %>%
  tibble::as_tibble() %>%
  dplyr::transmute(
    com_id = COM.NO %>% as.integer(),
    com_label = COM.ID %>% as.character(),
    com_name = COM.NAME %>% as.character(),
    former_range_code = COM.FORMER.RANGE %>% as.character(),
    range_decline_id = COM.RANGE.DECLINE %>% as.integer(),
    occ_decline_id = COM.OCC.DECLINE %>% as.integer(),
    com_tec_listing = COM.TEC.LISTING %>% as.integer(),
    com_original_area = COM.ORIG.AREA %>% as.double(),
    com_area_accuracy = COM.AREA.ACC %>% as.double(),
    preliminary = COM.PRELIMINARY %>% as.character(),
    status = COM.STATUS %>% as.character()
  ) %>%
  dplyr::left_join(former_range, by = "former_range_code") %>%
  dplyr::left_join(range_decline, by = "range_decline_id") %>%
  dplyr::left_join(occ_decline, by = "occ_decline_id") %>%
  dplyr::select(-former_range_code, -range_decline_id, -occ_decline_id)

readr::write_csv(communities, path = here::here("data", "tec_communities.csv"))

com_short <- communities %>% dplyr::select(com_id, com_label, com_name)
```

### Community Recommendations

```{r make_com_recommendations}
recommendations <- tec$RECOMMENDATIONS %>%
  dplyr::transmute(
    recommendation_code = REC.CODE %>% as.character(),
    recommendation = REC.DESC %>% as.character()
  )

com_recommendations <- tec$COMMUNITY_RECOMMENDATIONS %>%
  dplyr::transmute(
    com_id = COM.NO %>% as.integer(),
    recommendation_id = CREC.NO %>% as.integer(),
    recommended_on = CREC.DATE %>% as.character(),
    recommendation_code = CREC.REC.CODE %>% as.character(),
    com_recommendation = CREC.DESC %>% as.character()
  ) %>%
  dplyr::left_join(com_short, by = "com_id") %>%
  dplyr::left_join(recommendations, by = "recommendation_code")

readr::write_csv(com_recommendations, path = here::here("data", "tec_com_recommendations.csv"))
```

### Community Publications

```{r make_com_publications}
publications <- tec$PUBLICATIONS %>%
  dplyr::transmute(
    publication_id = PUB.NO %>% as.integer(),
    title = PUB.TITLE %>% as.character(),
    author = PUB.AUTHOR %>% as.character()
    # empty:
    # published_on = PUB.DATE %>% parse_date_time(., orders = orders, tz = tz),
    # published_with = PUB.PLACE %>% as.character()
  )

com_publications <- tec$COMMUNITY_PUBLICATIONS %>%
  dplyr::transmute(
    com_id = COM.NO %>% as.integer(),
    publication_id = CP.PUB.NO %>% as.integer(),
  ) %>%
  dplyr::left_join(publications, by = "publication_id") %>%
  dplyr::left_join(com_short, by = "com_id")

readr::write_csv(com_publications, path = here::here("data", "tec_com_publications.csv"))
```

### Community Reviews

```{r make_com_reviews}
reviews <- tec$REVIEWS %>%
  dplyr::transmute(
    review_id = REV.NO %>% as.integer(),
    review_date = REV.DATE %>% parse_date_time(., orders = orders, tz = tz),
    review_panel = REV.PANEL %>% as.character()
  )

com_reviews <- tec$COMMUNITY_REVIEWS %>%
  dplyr::transmute(
    com_id = COM.NO %>% as.integer(),
    review_id = CR.REV.NO %>% as.integer()
  ) %>%
  dplyr::left_join(com_short, by = "com_id") %>%
  dplyr::left_join(reviews, by = "review_id")

readr::write_csv(com_reviews, path = here::here("data", "tec_com_reviews.csv"))
```

### Community Actions

```{r make_com_actions}
actions <- tec$ACTIONS %>%
  dplyr::transmute(
    action_id = ACTION.CODE %>% as.character(),
    description = ACTION.DESC %>% as.character()
  )

com_actions <- tec$COMMUNITY_ACTIONS %>%
  dplyr::transmute(
    com_id = COM.NO %>% as.integer(),
    com_action_id = CACT.NO %>% as.integer(),
    com_action_date = CACT.DATE %>% parse_date_time(., orders = orders, tz = tz),
    action_id = CACT.ACTION.CODE %>% as.character(),
    com_action_description = CACT.DESC %>% as.character()
  ) %>%
  dplyr::left_join(com_short, by = "com_id") %>%
  dplyr::left_join(actions, by = "action_id")

readr::write_csv(com_actions, path = here::here("data", "tec_com_actions.csv"))
```

### Community History, Area Decline

```{r make_com_history}
area_decline <- tec$AREA_DECLINE %>%
  dplyr::transmute(
    area_decline_id = AD.CODE %>% as.integer(),
    area_decline = AD.DESC %>% as.character()
  )

com_history <- tec$HISTORY %>%
  dplyr::transmute(
    com_id = COM.NO %>% as.integer(),
    history_id = HIST.NO %>% as.character(),
    history_date = HIST.DATE %>% as.character(),
    area_decline_id = HIST.AD.CODE %>% as.integer(),
    comment = HIST.COMMENT %>% as.character()
  ) %>%
  dplyr::left_join(com_short, by = "com_id") %>%
  dplyr::left_join(area_decline, by = "area_decline_id")
```

## Conservation listings

```{r get_tec_ccl}
tec_cons_cat <- tec$CATEGORY_TYPES %>%
  dplyr::transmute(
    category_code = CT.TYPE %>% as.character(),
    category_label = CT.DESC %>% as.character(),
    authority = CT.AUTHORITY.CODE %>% as.character()
  )

tec_cons_crit <- tec$CRITERIA_CODES %>%
  dplyr::transmute(
    criterion_code = CRIT.CODE %>% as.character(),
    criterion_description = CRIT.DESC %>% as.character()
  )
readr::write_csv(tec_cons_crit, path = here::here("data", "tec_cons_crit.csv"))

# Using a built-in function to turn uppercase into lowercase? Nah. Hold my beer.
authorities <- tec$AUTHORITIES # A lookup for upper cased authorities vs lower cased authorities.
endorsement <- tec$ENDORSED_BY # another lookup for lower case.
readr::write_csv(endorsement, path = here::here("data", "tec_endorsement.csv"))

# primary
tec_cons_listing_categories <- tec$CATEGORIES %>%
  dplyr::transmute(
    com_id = COM.NO %>% as.integer(),
    effective_from = CAT.EFFECT.DATE %>% parse_as_datetime(),
    category_code = CAT.CT.TYPE %>% as.character(),
    cat_comment = CAT.COMMENT %>% as.character(),
    cat_review_date = CAT.REVIEW.DATE %>% parse_as_datetime(),
    cat_endorsed_code = CAT.ENDORSED.CODE %>% as.character(),
    cat_endorsed_date = CAT.ENDORSED.DATE %>% parse_as_datetime(),
    cat_endorsed_by_minister = CAT.ENDORSED.BY.MINISTER %>% as.character()
  ) %>%
  dplyr::left_join(com_short, by = "com_id") %>%
  dplyr::left_join(tec_cons_cat, by = "category_code") %>%
  tibble::rowid_to_column("source_id")

tec_cons_listing_criteria <- tec$CATEGORY_CRITERIA %>%
  dplyr::transmute(
    com_id = COM.NO %>% as.integer(),
    effective_from = CAT.EFFECT.DATE %>% parse_as_datetime(),
    criterion_code = CC.CRIT.CODE %>% as.character()
  ) %>%
  dplyr::left_join(com_short, by = "com_id") %>%
  dplyr::left_join(tec_cons_crit, by = "criterion_code")
# join com_short, criteria codes

# TODO: load cons crit from IUCN RLE into TSC, map resulting codes to:
# tec_cons_crit$criterion_code

## Check for differences between categories and criteria and then join criteria to categories for all communities
tec_cons_cat_mis_crit <- tec_cons_listing_categories %>%
  anti_join(tec_cons_listing_criteria, by = c("com_id", "effective_from")) # 132

tec_cons_crit_mis_cat <- tec_cons_listing_criteria %>%
  anti_join(tec_cons_listing_categories, by = c("com_id", "effective_from")) # 0

tec_cons_listing <- tec_cons_listing_categories %>%
  left_join(tec_cons_listing_criteria, by = c("com_id", "effective_from", "com_label", "com_name"))

## Extract criterion_codes to manual map all criteria
all_crit_map <- tec_cons_listing %>%
  dplyr::distinct(criterion_code)
readr::write_csv(all_crit_map, path = here::here("data", "all_tec_conscrit.csv"))
```

## Occurrences

```{r get_tec_occ, message = FALSE, warning = FALSE}
reliability <- tec$RELIABILITY %>% dplyr::transmute(
  reliability_id = BR.CODE %>% as.character(),
  reliability = BR.DESC %>% as.character()
)

readr::write_csv(reliability, path = here::here("data", "tec_reliability.csv"))

tec_occ <- tec$OCCURRENCES %>% ## most of this will get added to comments
  tibble::as_tibble() %>%
  dplyr::transmute(
    # IDs
    occ_id = OCC.UNIQUE.ID %>% as.integer(),
    com_id = COM.NO %>% as.integer(),
    occ_no = OCC.NO %>% as.integer(),
    source_code = OCC.SOURCE.CODE %>% as.character(),

    # spatial references
    boundary_id = BDY.ID %>% as.integer(),
    boundary_desc = OCC.BOUNDARY.DESC %>% as.character(),
    # boundary_no = OCC.NO.BOUNDARY %>% as.integer, # empty
    buffer_radius = OCC.BUFFER.RADIUS %>% as.integer(),
    original_area = OCC.ORIGINAL.AREA %>% as.double(),
    area_accuracy = OCC.AREA.ACCURACY %>% as.double(),

    # occ details
    species_desc = OCC.SPECIES.DESC %>% as.character(),
    commonwealth_desc = OCC.COMMONWEALTH.DESC %>% as.character(),
    confidential_id = OCC.CONFIDENTIAL %>% as.integer(),
    reliability_id = OCC.BR.CODE %>% as.character(),
    occ_desc = OCC.DESC %>% as.character(),
    status_code = OCC.STATUS.CODE %>% as.logical(),
    ctrc_sys = OCC.CTRC.SYS %>% as.integer(), # FK CTRC_SYSTEMS
    ctrc_recommendation = OCC.CTRC.RECOMMENDATION %>% as.character(),
    cwealth_listing = OCC.CWEALTH.LISTING %>% as.character(),
    data = OCC.DATA %>% as.character(),
    other = OCC.OTHER %>% as.character(),
    soil = OCC.SOIL %>% as.character(),
    surf_geology = OCC.SURF.GEOLOGY %>% as.character(),
    land_element = OCC.LAND.ELEMENT %>% as.character(),
    water = OCC.WATER %>% as.character(),
    drainage = OCC.DRAINAGE %>% as.character(),
    com_structure = OCC.COM.STRUCTURE %>% as.character(),
    classification = OCC.CLASSIFICATION %>% as.character(),
    other_attr = OCC.OTHER.ATTR %>% as.character(),
    

    # spatial lookups
    beard_dist_code = OCC.BEARD.DIST.CODE %>% as.character(),
    beard_map_code = OCC.BEARD.MAP.CODE %>% as.character(),
    beard_desc = OCC.BEARD.DESC %>% as.character(),
    ibra_reg_code = OCC.IBRA.REG.CODE %>% as.character(),
    dola_ref = OCC.DOLA.REF %>% as.character(),
    bush_forever_site_no = OCC.BUSH.FOREVER.SITE.NO %>% as.integer(),
    zone_code = OCC.ZONE.CODE %>% as.character(),

    # audit
    created_by = USERNAME %>% as.character(),
    date_encountered_on = OCC.DATE.ENTERED %>%
      lubridate::parse_date_time(., orders = orders, tz = tz),
    date_changed_on = OCC.DATE.EDITED %>%
      as.character() %>%
      lubridate::parse_date_time(., orders = orders, tz = tz)
  ) %>%
  dplyr::left_join(com_short, by = "com_id") %>%
  # dplyr::left_join(confidentiality, by = "confidential_id") %>%
  dplyr::left_join(reliability, by = "reliability_id") %>%
  dplyr::select(-confidential_id, reliability_id)

occ_short <- tec_occ %>% 
   dplyr::transmute(
     occ_id = occ_id,
     boundary_id = boundary_id,
     boundary_desc = boundary_desc,
     com_id = com_id,
     com_label = com_label,
     com_name = com_name)

## Create occurrence data tables for each card in TSC

hab_comp <- tec_occ %>%
  dplyr::filter(!is.na(occ_id) & !is.na(com_id) & occ_id!=0) %>% 
  dplyr::transmute(
    source = 10,
    occ_id = occ_id,
    land_element = land_element,
    drainage = drainage,
    soil = soil) %>% 
  filter(land_element != "") %>% 
  filter(drainage != "") %>% 
  filter(soil != "")

hab_comp %>%
  dplyr::select(land_element) %>%
  distinct() %>% 
  readr::write_csv(path = here::here("data", "tec_land_element.csv"))

hab_comp %>%
  dplyr::select(soil) %>%
  distinct() %>% 
  readr::write_csv(path = here::here("data", "tec_soil.csv"))

hab_comp %>%
  dplyr::select(drainage) %>%
  distinct() %>% 
  readr::write_csv(path = here::here("data", "tec_drainage.csv"))
```

### Occurrence Actions

```{r make_occ_actions}
occ_actions <- tec$OCCURRENCE_ACTIONS %>%
  dplyr::transmute(
    occ_id = OCC.UNIQUE.ID %>% as.integer(),
    occ_action_id = OACT.NO %>% as.integer(),
    occ_action_date = OACT.DATE %>% parse_date_time(., orders = orders, tz = tz),
    occ_action_description = OACT.DESC %>% as.character(),
    username = USERNAME %>% as.character(),
    action_id = OACT.ACTION.CODE %>% as.character()
  ) %>%
  dplyr::left_join(occ_short, by = "occ_id") %>%
  dplyr::left_join(actions, by = "action_id")
```

### Occurrence Recommendations

```{r make_occ_recommendations}
occ_recommendations <- tec$OCCURRENCE_RECOMMENDATIONS %>%
  dplyr::transmute(
    occ_id = OCC.UNIQUE.ID %>% as.integer(),
    rank = OREC.RANK %>% as.character(),
    recommended_on = OREC.DATE %>% as.character(),
    recommendation_code = OREC.REC.CODE %>% as.character(),
    occ_recommendation = OREC.DESC %>% as.character(),
    username = USERNAME %>% as.character()
  ) %>%
  dplyr::left_join(occ_short, by = "occ_id") %>%
  dplyr::left_join(recommendations, by = "recommendation_code")

```

### Occurrence Extent

```{r make_occ_extent}
sources <- tec$SOURCES %>%
  dplyr::transmute(
    source_code = SOURCE.CODE %>% as.character(),
    source = SOURCE.DESC %>% as.character()
  )

readr::write_csv(sources, path = here::here("data", "tec_sources.csv"))

occ_extent <- tec$EXTENTS %>%
  dplyr::transmute(
    occ_id = OCC.UNIQUE.ID %>% as.integer(),
    EXT.NO = EXT.NO %>% as.character(),
    EXT.DATE = EXT.DATE %>% as.character(),
    source_code = EXT.SOURCE.CODE %>% as.character(),
    EXT.AREA = EXT.AREA %>% as.character(),
    EXT.AREA.ACC = EXT.AREA.ACC %>% as.character(),
    area_decline_id = EXT.AD.CODE %>% as.integer(),
    EXT.COMMENT = EXT.COMMENT %>% as.character(),
    USERNAME = USERNAME %>% as.character()
  ) %>%
  dplyr::left_join(occ_short, by = "occ_id") %>%
  dplyr::left_join(sources, by = "source_code") %>%
  dplyr::left_join(area_decline, by = "area_decline_id")

```

### Additional Data

```{r make_occ_additional_data}
items <- tec$ITEMS %>%
  dplyr::transmute(
    item_code = ITEM.CODE %>% as.character(),
    item = ITEM.DESC %>% as.character()
  )

readr::write_csv(items, path = here::here("data", "tec_items.csv"))

occ_additional_data <- tec$ADDITIONAL_DATA %>%
  dplyr::transmute(
    occ_id = OCC.UNIQUE.ID %>% as.integer(),
    additional_data_id = ADD.NO %>% as.integer(),
    item_code = ADD.ITEM.CODE %>% as.character(),
    description = ADD.DESC %>% as.character(),
    username = USERNAME %>% as.character()
  ) %>%
  dplyr::left_join(occ_short, by = "occ_id") %>%
  dplyr::left_join(items, by = "item_code")
```

### Occurrence Maps
Names of physical maps describing one or multiple occurrences.

```{r make_occ_maps}
maps <- tec$MAPS
readr::write_csv(maps, path = here::here("data", "tec_maps.csv"))

occ_maps <- tec$OCCURRENCE_MAPS
readr::write_csv(occ_maps, path = here::here("data", "tec_occ_maps.csv"))

```

### Biological Processes

```{r make_occ_biol_process}
occ_biol_process <- tec$BIOL_PROCESSES %>%
  dplyr::transmute(
    occ_id = OCC.UNIQUE.ID %>% as.integer(),
    biol_process_id = BIOL.NO %>% as.integer(),
    biol_process = BIOL.PROCESS %>% as.character(),
    username = USERNAME %>% as.character()
  ) %>%
  dplyr::left_join(occ_short, by = "occ_id")
```

### Non-biological Processes

```{r make_occ_nonbiol_process}
occ_nonbiol_process <- tec$NON_BIOL_PROCESSES %>%
  dplyr::transmute(
    occ_id = OCC.UNIQUE.ID %>% as.integer(),
    nonbiol_process_id = NBIO.NO %>% as.integer(),
    nonbiol_process = NBIO.PROCESS %>% as.character(),
    username = USERNAME %>% as.character()
  ) %>%
  dplyr::left_join(occ_short, by = "occ_id")
```

## Fire History

```{r make_occ_fire_history}
fire_history <- tec$FIRE_HISTORY %>%
  dplyr::transmute(
    occ_id = OCC.UNIQUE.ID %>% as.integer(),
    fire_history_id = FIRE.NO %>% as.integer(),
    fire_history_date = FIRE.DATE %>% as.character(),
    fire_history_comment = FIRE.COMMENT %>% as.character(),
    username = USERNAME %>% as.character()
  ) %>%
  dplyr::left_join(occ_short, by = "occ_id")
```

## Fauna Occurrences
There is another separate group of occurrences:

* Occurrence Species
* Occurrence Species INI (contains an external db config)
* Occurrence Fauna
* Species Roles
* Fauna Taxa
* Fauna Groups
* Fauna Conservation Codes

What is the overlap to the Threatened Fauna DB in terms of meaning and data flow?

```{r make_fauna_occ}
# lookup tables
fauna_conservation_codes <- tec$FAUNA_CONSERVATION_CODES %>%
  dplyr::transmute(
    conservation_code = CONSV.CODE %>% as.character(),
    conservation_code_description = CONSV.DESC %>% as.character()
  )

fauna_groups <- tec$FAUNA_GROUPS # paraphyletic groups

species_roles <- tec$SPECIES_ROLES %>%
  dplyr::transmute(
    species_role_code = SP.ROLE.CODE %>% as.character(),
    species_role = SP.ROLE.DESC %>% as.character()
  )
readr::write_csv(species_roles, path = here::here("data", "tec_species_roles.csv"))

# primary data
occ_fauna <- tec$OCCURRENCE_FAUNA %>%
  dplyr::transmute(
    occ_id = OCC.UNIQUE.ID %>% as.integer(),
    taxon_id = OF.TAXON.ID %>% as.character(),
    species_code = OF.SPCODE %>% as.character(),
    species_role_code = OF.SP.ROLE.CODE %>% as.character(),
    comments = OF.VOUCHER.NO %>% as.character(),
    username = USERNAME %>% as.character(),
  ) %>%
  dplyr::left_join(occ_short, by = "occ_id") %>%
  dplyr::left_join(species_roles, by = "species_role_code")

occ_species <- tec$OCCURRENCE_SPECIES %>%
  dplyr::transmute(
    occ_id = OCC.UNIQUE.ID %>% as.integer(), ## Occ_id links to boundary id
    taxon_id = SPEC.TAXON.ID %>% as.character(),
    species_code = SPEC.SPCODE %>% as.character(),
    species_role_code = SPEC.SP.ROLE.CODE %>% as.character(),
    comments = SPEC.VOUCHER.NO %>% as.character(),
    username = USERNAME %>% as.character(),
  ) %>%
  dplyr::left_join(occ_short, by = "occ_id") %>%
  dplyr::left_join(species_roles, by = "species_role_code")

# occ_species %>% DT::datatable(.)
```

## Surveys
`Surveys` are full site visits with a complete set of measurements.

```{r make_surveys,warning=FALSE}
# lookups
impacts <- tec$THREAT_IMPACTS %>%
  dplyr::transmute(
    impact_code = IMP.CODE %>% as.character(),
    impact = IMP.DESC %>% as.character()
  )
readr::write_csv(impacts, path = here::here("data", "tec_impacts.csv"))

threats <- tec$THREATS %>%
  dplyr::transmute(
    threat_code = THREAT.CODE %>% as.character(),
    threat = THREAT.DESC %>% as.character()
  )
readr::write_csv(threats, path = here::here("data", "tec_threats.csv"))

conditions <- tec$CONDITIONS %>%
  dplyr::transmute(
    condition_code = COND.CODE %>% as.character(),
    condition = COND.DESC %>% as.character()
  )
readr::write_csv(conditions, path = here::here("data", "tec_conditions.csv"))

# primary
com_threats <- tec$COMMUNITY_THREATS %>%
  dplyr::transmute(
    com_id = COM.NO %>% as.integer(),
    id = CTHR.NO %>% as.character(),
    date = CTHR.DATE %>% as.character(),
    threat_code = CTHR.THREAT.CODE %>% as.character(),
    description = CTHR.DESC %>% as.character()
  ) %>%
  dplyr::left_join(threats, by = "threat_code")

surveys <- tec$SURVEYS %>%
  dplyr::transmute(
    occ_id = OCC.UNIQUE.ID %>% as.integer(),
    survey_id = SUR.NO %>% as.integer(),
    surveyed_on = SUR.DATE %>%
      lubridate::parse_date_time(., orders = orders, tz = tz),
    surveyed_by = SUR.SURVEYOR %>% as.character(),
    survey_comments = SUR.COMMENTS %>% as.character(),
    username = USERNAME %>% as.character()
  ) %>%
  dplyr::left_join(occ_short, by = "occ_id") %>%
  dplyr::mutate(source_id = glue::glue("{boundary_id}{survey_id}"))

readr::write_csv(surveys, path = here::here("data", "tec_surveys.csv"))

survey_threats <- tec$SURVEY_THREATS %>%
  dplyr::transmute(
    occ_id = OCC.UNIQUE.ID %>% as.integer(),
    survey_id = SUR.NO %>% as.integer(),
    threat_rank = THR.RANK %>% as.integer(),
    threat_code = THR.THREAT.CODE %>% as.character(),
    threat_percent = THR.PERCENT %>% as.double(),
    historic_impact_code = THR.HIST.IMP.CODE %>% as.character(),
    potential_impact_code = THR.POT.IMP.CODE %>% as.character(),
    modification = THR.MODIFICATION %>% as.character(),
    comments = THR.COMMENTS %>% as.character(),
    username = USERNAME %>% as.character(),
  ) %>%
  dplyr::left_join(occ_short, by = "occ_id") %>%
  dplyr::left_join(threats, by = "threat_code") %>%
  dplyr::left_join(impacts, by = c("historic_impact_code" = "impact_code")) %>%
  dplyr::rename(historic_impact = impact) %>%
  dplyr::left_join(impacts, by = c("potential_impact_code" = "impact_code")) %>%
  dplyr::rename(potential_impact = impact)

survey_conditions <- tec$SURVEY_CONDITIONS %>%
  dplyr::transmute(
    occ_id = OCC.UNIQUE.ID %>% as.integer(),
    survey_id = SUR.NO %>% as.integer(),
    condition_code = SCON.COND.CODE %>% as.character(),
    condition_percent = SCON.PERCENT %>% as.double(),
    comments = SCON.COMMENTS %>% as.character(),
    username = USERNAME %>% as.character()
  ) %>%
  dplyr::left_join(occ_short, by = "occ_id") %>%
  dplyr::left_join(conditions, by = "condition_code")

readr::write_csv(survey_conditions, path = here::here("data", "tec_survey_conditions.csv"))
```

Out of `r nrow(surveys)` surveys, there are only `r length(unique(surveys$survey_id))` distinct survey_id's.
With `r length(unique(surveys$surveyed_on))`, this means that a survey_id does not denote an individual
visit of a TEC boundary.

## Site Visits
`Site visits` are quick site visits with a partial set of measurements.

```{r make_sites}
datum <- tec$DATUM %>%
  dplyr::transmute(
    datum_code = DATUM.CODE %>% as.character(),
    datum = DATUM.DESC %>% as.character(),
    semi_major_axis = SEMI.MAJOR.AXIS %>% as.double(),
    inverse_flattening = INVERSE.FLATTENING %>% as.double()
  )
readr::write_csv(datum, path = here::here("data", "tec_datum.csv"))

sites <- tec$SITES %>%
  dplyr::transmute(
    occ_id = OCC.UNIQUE.ID %>% as.integer(),
    site_code = S.ID %>% as.character(),
    datum_code = S.DATUM.CODE %>% as.character(),
    latitude = S.LATITUDE %>% as.double(),
    longitude = S.LONGITUDE %>% as.double(),
    comments = S.COMMENTS %>% as.character(),
    # S.LATITUDE.PREF = S.LATITUDE.PREF  %>% as.character, # wtf?
    # S.LONGITUDE.PREF = S.LONGITUDE.PREF  %>% as.character, # wut?
    created_by = USERNAME %>% as.character(),
    changed_on = S.DATE.EDITED %>% parse_date_time(., orders = orders, tz = tz),
    permanently_marked = S.PERMANENTLY.MARKED %>% as.character(), # "", "Y"
    location = S.LOCATION %>% as.character(),
    habitat = S.HABITAT %>% as.character(),
    soil = S.SOIL %>% as.character(),
    # rock_type = S.ROCK.TYPE %>% as.character(), # empty
    # parent_material = S.PARENT.MATERIAL %>% as.character(), # empty
    vegetation = S.VEGETATION %>% as.character(),
    # rock_pile_notes = S.ROCK.PILE.NOTES %>% as.character(), # empty
    site_notes = S.SITE.NOTES %>% as.character()
  ) %>%
  dplyr::left_join(occ_short, by = "occ_id") %>%
  dplyr::left_join(datum, by = "datum_code")

readr::write_csv(sites, path = here::here("data", "tec_sites.csv"))

site_visit <- tec$SITE_VISITS %>%
  dplyr::transmute(
    site_visit_id = SITE.VISIT.ID %>% as.integer(),
    site_code = S.ID %>% as.character(),
    site_visit_date = SV.VISIT.DATE %>%
      lubridate::parse_date_time(., orders = orders, tz = tz),
    project_code = SV.PROJ.CODE %>% as.character(),
    site_visit_described_by = SV.DESCRIBED.BY %>% as.character(),
    site_visit_described_by_notes = SV.DESCRIBED.BY.NOTES %>% as.character(),
    seasonal_conditions = SV.SEASONAL.CONDITIONS %>% as.character(),
    observation_type = SV.OBSERVATION.TYPE %>% as.character(),
    observation_quality = SV.OBSERVATION.QUALITY %>% as.character(),
    plant_id_quality = SV.PLANT.ID.QUALITY %>% as.character(),
    site_dimensions = SV.SITE.DIMENSIONS %>% as.character(),
    site_uniformity = SV.SITE.UNIFORMITY %>% as.character(),
    site_status = SV.SITE.STATUS %>% as.character(),
    photo_numbers = SV.PHOTO %>% as.character(),
    vegetation_condition = SV.VEGETATION.CONDITION %>% as.character(),
    fire_age = SV.FIRE.AGE %>% as.character(),
    fire_notes = SV.FIRE.NOTES %>% as.character(),
    observation_notes = SV.OBSERVATION.NOTES %>% as.character()
  )

bdy_w_one_site <- tec_bdy %>%
  filter(S_ID_COUNT == 1) %>%
  magrittr::extract2("BDY_ID") # 121578 with a site ID = 1, which measn they are duplicates

sites_keep <- tec_site %>%
  dplyr::filter(!(BDY_ID %in% bdy_w_one_site)) ## These are the sites we want to keep as they are not just boundary duplicates

# coll code and number indicates voucher specimens
voucher_specimens <- tec$SITE_SPECIES %>%
  dplyr::transmute(
    site_species_id = SITE.SPECIES.ID %>% as.character(),
    site_visit_id = SITE.VISIT.ID %>% as.integer(),
    name_id = SSP.NAME.ID %>% as.character(),
    species_code = SSP.SPCODE %>% as.character(),
    height = SSP.HEIGHT %>% as.character(),
    collector_code = SSP.COLLECTOR.CODE %>% as.character(),
    collection_number = SSP.COLLECTION.NUMBER %>% as.character(),
    notes = SSP.NOTES %>% as.character()
  ) %>%
  dplyr::left_join(site_visit, by = "site_visit_id")
```

There are `r nrow(sites)` point locations known as TEC sites.

```{r show_sites_map, fig.height=5, fig.width=7}
leaflet(width = 800, height = 600) %>%
  addProviderTiles("Esri.WorldImagery", group = "Aerial") %>%
  addProviderTiles("OpenStreetMap.Mapnik", group = "Place names") %>%
  clearBounds() %>%
  addAwesomeMarkers(
    data = sites,
    lng = ~longitude, lat = ~latitude,
    icon = leaflet::makeAwesomeIcon(icon = "leaf"),
    label = ~ paste(site_code),
    popup = ~ paste(
      "<h3>Site", site_code, "</h3>",
      "<strong>Community</strong>", com_label, "<br/>",
      "<strong>Created by</strong>", created_by, "on", changed_on, "<br/>",
      "<strong>Comments</strong>", comments, "<br/>",
      "<strong>Permanent</strong>", permanently_marked, "<br/>",
      "<strong>Location</strong>", location, "<br/>",
      "<strong>Habitat</strong>", habitat, "<br/>",
      "<strong>Soil</strong>", soil, "<br/>",
      "<strong>Vegetation</strong>", vegetation, "<br/>",
      "<strong>Site notes</strong>", site_notes, "<br/>"
    ),
    group = "Site points",
    clusterOptions = markerClusterOptions()
  ) %>%
  addLayersControl(
    baseGroups = c("Aerial", "Place names"),
    overlayGroups = c("Site points"),
    options = layersControlOptions(collapsed = FALSE)
  )
```

## Recovery Plans

```{r make_recovery_plans}
recovery_plans <- tec$INTERIM_RECOVERY_PLANS %>%
  dplyr::transmute(
    recovery_plan_id = IRP.NO %>% as.character(),
    com_id = COM.NO %>% as.integer(),
    endorsed_on = IRP.DATE.ENDORSED %>% parse_date_time(., orders = orders, tz = tz),
    ends_on = IRP.END.DATE %>% parse_date_time(., orders = orders, tz = tz),
    author = IRP.AUTHOR %>% as.character(),
    reviewed_on = IRP.DATE.REVIEWED %>% parse_date_time(., orders = orders, tz = tz),
    comments = IRP.COMMENTS %>% as.character()
  ) %>%
  dplyr::left_join(com_short, by = "com_id")

readr::write_csv(recovery_plans, path = here::here("data", "tec_recovery_plans.csv"))

```

## Occurrence Boundaries
Boundaries are named after the first site (see [site visits]) captured inside the respective boundary.

```{r make_tec_bdy, message = FALSE}
tec_bdy %>%
  filter(BDY_ID == 0) %>%
  nrow() # Six boundaries have no boundary id

survey_cae <- surveys %>%
  left_join(tec_bdy, by = c("boundary_id" = "BDY_ID")) %>%
  left_join(tec_occ, by = c("occ_id", "com_id", "com_label", "com_name", "boundary_id", "boundary_desc")) %>%
  left_join(communities, by = c("com_id", "com_label", "com_name")) %>% 
  clean_names()

tec_bdy_cae_build <- survey_cae %>%
  dplyr::mutate(description1 = ifelse(
      is.na(first_s_id),
      glue::glue(
        "Boundary ID {boundary_id} named ",
        "{boundary_id} for lack of sites within."
      ),
      glue::glue(
        "Boundary ID {boundary_id} named ",
        "{first_s_id} after first site observed within. ",
        "Survey comments: {survey_comments}"
      ))) %>% 
  dplyr::mutate(description2 = glue::glue(
        "Revised on: {date_changed_on};\n",
        "Site description: {occ_desc} {species_desc} {reliability_id};\n",
        "Commonwealth:  {commonwealth_desc} {cwealth_listing};\n",
        "Area assessment: {data} {other};\n",
        "Habitat composition: {soil} {surf_geology} {land_element} {water} {drainage} {com_structure} {classification} {other_attr} {reliability}."
    )) %>% 
  dplyr::transmute(
    # occ_id = occ_id,
    community = com_id,
    code = boundary_id,
    name = com_name,
    description = glue::glue(
        "{description1};\n",
        "{description2}."
    ),
    area_type = 10, # 10 bound, 11 buffer, 12 site point
    source = 13, # TEC bdy
    source_id = source_id,
    encountered_on = surveyed_on,
    encountered_by = 1,
    geom = geometry %>%
      sf::st_convex_hull(.) %>%
      sf::st_buffer(., 0.00001) %>%
      geojsonsf::sfc_geojson(.)
  )

tec_bdy_cae <- tec_bdy_cae_build %>%
  dplyr::filter(community != "NA")%>%
  dplyr::filter(!is.na(encountered_on))%>%
  dplyr::filter(geom != "null")
```

Some boundaries were digitised from a polygonised raster remote sensing product. This results in
a spray of numerous polygons, most of which were never visited in person.

Name and shame: 

```{r show_tec_cae_large}
numerous_communities <- tec_bdy_cae %>%
  dplyr::group_by(community) %>%
  dplyr::tally() %>%
  dplyr::arrange(-n) %>%
  filter(n > 400)

numerous_communities

fat_filter <- numerous_communities %>%
  magrittr::extract2("community") %>%
  paste0(collapse = "|")
```

## Occurrence Buffers

```{r make_tec_buf}
# tec_buf_cae <- tibble::tibble(
#     community = tec_buf$COM_ID,
#     code=tec_buf$FIRST_S_ID %||% tec_buf$BDY_ID,
#     name=tec_buf$FIRST_S_ID %||% tec_buf$BDY_ID,
#     description = ifelse(
#         is.na(tec_buf$FIRST_S_ID),
#         glue::glue("Buffered Boundary ID {tec_buf$BDY_ID} named",
#                    " {tec_buf$BDY_ID} for lack of sites within."),
#         glue::glue("Buffered Boundary ID {tec_buf$BDY_ID} named",
#                    " {tec_buf$FIRST_S_ID} after first site observed within.")
#     ),
#     area_type = 11, # 10 bound, 11 buffer, 12 site point
#     source = 14, # TEC buf
#     source_id = tec_buf$OCC_UNIQUE,
#     encountered_on=default_date,
#     encountered_by=1,
#     geom = tec_buf$geometry %>%
#         sf::st_convex_hull(.) %>%
#         sf::st_buffer(., 0.00001) %>%
#         geojsonsf::sfc_geojson(.)
# )
```

## Occurrence Sites

```{r make_tec_sites}
tec_site %>%
  filter(BDY_ID == 0) %>%
  nrow() # 1666

site_visit_cae <- site_visit %>%
  left_join(tec_site, by = c("site_code" = "S_ID")) %>%
  left_join(tec_occ, by = c("OCC_UNIQUE" = "occ_id")) %>%
  left_join(communities, by = c("com_id", "com_label", "com_name")) %>% 
  clean_names()

tec_site_cae_build <- site_visit_cae %>%
  dplyr::transmute(
    # occ_id = OCC_UNIQUE,
    community = com_id,
    code = site_code,
    name = site_code,
    description = glue::glue( "Revised on: {date_changed_on};\n",
       "Site ID {site_code} inside TEC Boundary {bdy_id};\n",
        "Site description: {occ_desc} {species_desc} {reliability_id};\n",
        "Commonwealth:  {commonwealth_desc} {cwealth_listing};\n",
        "Area assessment: {data} {other};\n",
        "Habitat composition: {soil} {surf_geology} {land_element} {water} {drainage} {com_structure} {classification} {other_attr} {reliability}."
    ),
    area_type = 12, # 10 bound, 11 buffer, 12 site point
    source = 15, # TEC sit
    source_id = site_visit_id,
    encounter_type = 2, # https://tsc.dbca.wa.gov.au/admin/occurrence/encountertype/2/change/ = survey
    encountered_on = site_visit_date,
    encountered_by = 1,
    point = geometry %>% geojsonsf::sfc_geojson(.)
  )

tec_site_cae <- tec_site_cae_build %>%
  dplyr::filter(community != "NA")%>%
  dplyr::filter(!is.na(encountered_on))%>%
  dplyr::filter(point != "null")
```

# Current conservation lists (TSC)

## Conservation criteria

Conservation criteria Data from TSC is extracted through the TSC API and
transformed into a useable format for manual mapping to tec.

A manual step annotated legacy conservation criteria exported from TEC to
conservation criteria IDs in TSC in a spreadsheet.

```{r get_tsc_ccl, message = FALSE}
tsc_conslists_com <- "conservationlist" %>%
  wastdr::wastd_GET(
    api_url = prod,
    query = c(scope_communities = TRUE)
  ) %>%
  magrittr::extract2("features") %>%
  {
    tibble::tibble(
      list_id = purrr::map_int(., "id"),
      list_code = purrr::map_chr(., "code"),
      label = purrr::map_chr(., "label"),
      scope_communities = purrr::map_chr(., "scope_communities"),
      scope_wa = purrr::map_chr(., "scope_wa"),
      scope_cmw = purrr::map_chr(., "scope_cmw")
    )
  }

# list_id of TSC cons lists applicable to communities
# DBCA_RLE 11
# WAPEC 12
# IUCN_RLE 16

# tsc_conscat$id = TSC ID for the cons category
# tsc_conscat$label = tec_cons_listing_categories$category_code
tsc_conscat <- "conservationcategory" %>%
  wastdr::wastd_GET(api_url = prod) %>%
  magrittr::extract2("features") %>%
  {
    tibble::tibble(
      tsc_category_id = purrr::map_int(., "id"),
      category_code = purrr::map_chr(., "code"),
      tsc_label = purrr::map_chr(., "label"),
      conservation_list = purrr::map_chr(., "conservation_list")
    )
  } %>%
  dplyr::filter(conservation_list %in% c(11, 12, 16))

tsc_cons_crit <-
  wastdr::wastd_GET("conservationcriterion", api_url = prod) %>%
  magrittr::extract2("features") %>%
  {
    tibble::tibble(
      id = purrr::map_int(., "id"),
      list_id = purrr::map_int(., "conservation_list"),
      rank = purrr::map_int(., "rank"),
      code = purrr::map_chr(., "code")
      # ,
      # label = purrr::map_chr(., "label")
    )
  } %>%
  dplyr::arrange(id, rank) %>%
  dplyr::left_join(tsc_conslists_com, by = "list_id")

# Load manual mapping of TEC cons criteria from CSV file, join to tec_cons_crit
tec_conscrit <- here::here("csv/tec_conscrit_w_tsc.csv") %>%
  readr::read_csv(
    col_types = cols(
      category_code = col_character(),
      tsc_category_id = col_character(),
      criterion_code = col_character(),
      criteria_code = col_character(),
      assigned_as_in_tsc = col_character(),
      tsc_criteria = col_character(),
      comments_MP = col_character(),
      actions = col_character()
    )
  )

tec_ccl <- tec_cons_listing %>%
  left_join(tec_conscrit, by = c("category_code", "criterion_code"))
```

## Occurrence lookup criteria

Occurrence lookup data from TSC are downloaded from the TSC API and transformed
into a usable format for manual mapping to TEC.

A manual step annotated lookup criteria exported from TSC to occurrence data in
TEC in a spreadsheet.

```{r get_tsc_occ_lookups, message=FALSE}
tsc_landforms <- "lookup-landform" %>%
  wastdr::wastd_GET(api_url = prod) %>%
  wastdr::wastd_parse() %>%
  readr::write_csv(path = here::here("data", "tsc_landforms.csv"))

tsc_drainage <- "lookup-drainage" %>%
  wastdr::wastd_GET(api_url = prod) %>%
  wastdr::wastd_parse() %>%
  readr::write_csv(path = here::here("data", "tsc_drainage.csv"))

tsc_soiltype <- "lookup-soiltype" %>%
  wastdr::wastd_GET(api_url = prod) %>%
  wastdr::wastd_parse() %>%
  readr::write_csv(path = here::here("data", "tsc_soiltype.csv"))

# Load manual mapping of TEC lookup criteria from CSV file, and join to relevant table

# habitat composition
tec_landforms <- here::here("csv/tec_landforms_w_tsc.csv") %>%
  readr::read_csv(
    col_types = cols(
      land_element = col_character(),
      tsc_landform = col_character(),
      tsc_criteria = col_character()
    ))

tec_drainage <- here::here("csv/tec_drainage_w_tsc.csv") %>%
  readr::read_csv(
    col_types = cols(
      drainage = col_character(),
      tsc_drainage = col_character(),
      tsc_criteria = col_character()
    ))

tec_hab_comp <- hab_comp %>%
  left_join(tec_landforms, by = c("land_element")) %>%
  left_join(tec_drainage, by = c("drainage")) %>%  
dplyr::transmute(
  source = source,
  source_id = occ_id,
  landform = tsc_landform,
  drainage = tsc_drainage) %>% 
dplyr::mutate(obstype = "HabitatComposition")
```

# Migrate legacy data (TEC to TSC)

In this section, the extracted and transformed data from TEC are loaded into TSC
using the TSC API. The code is collapsed; expand the code blocks to view the
process.

## Conservation listings

```{r make_tec_cl, message=FALSE}
# summarise criterion codes into one row per date
comm_info <- tec_ccl %>%
  dplyr::select(com_id, com_label, com_name) %>%
  distinct()

tec_cat_code <- tec_ccl %>%
  dplyr::group_by(com_id, effective_from, tsc_category_id) %>%
  dplyr::arrange(category_code) %>%
  dplyr::summarise(category_code = paste(category_code, collapse = ","))

tec_crit_code <- tec_ccl %>%
  dplyr::group_by(com_id, effective_from) %>%
  dplyr::arrange(criteria_code) %>%
  dplyr::summarise(criteria_code = paste(criteria_code, collapse = ","))

tsc_crit_code <- tec_ccl %>%
  dplyr::group_by(com_id, effective_from) %>%
  dplyr::arrange(tsc_criteria) %>%
  dplyr::summarise(tsc_criteria = paste(tsc_criteria, collapse = ",")) %>%
  dplyr::mutate(tsc_criteria = purrr::map(tsc_criteria, chr2int))

tec_tsc <- tec_cons_listing_categories %>%
  dplyr::left_join(tec_cat_code, by = c("com_id", "effective_from", "category_code")) %>%
  dplyr::left_join(tec_crit_code, by = c("com_id", "effective_from")) %>%
  dplyr::left_join(tsc_crit_code, by = c("com_id", "effective_from"))

tec_cl_tsc <- tec_tsc %>%
  dplyr::transmute(
    source = 3, # TaxonGaz.source TFA 1, TFL 2, TEC 3
    source_id = source_id %>% as.character(),
    scope = 0, # state 0, cwth 1, intl 2, ap 3
    status = 80,
    effective_from = effective_from,
    # effective_to = date_delisted,
    review_due = cat_review_date,
    community = com_label,
    category = tsc_category_id %>% as.list(),
    criteria = tsc_criteria
  ) %>%
  dplyr::filter(!is.na(category))

# dplyr::glimpse(tec_cl_tsc)
```

```{r load_tec_tcl, eval=FALSE}
# LONG RUNNING UPLOAD
tec_cl_tsc %>%
  wastdr::wastd_POST("community-conservationlisting")
```

## Occurrences

TEC refers to a single AOO as "occurrence". Occurrences may be geo-referenced as boundaries and/or
buffered boundaries (buffers) and/or through point sites within.

### Upload TEC boundaries to TSC

The TEC boundary upload excludes the heavyweight communities with more than 400 features

```{r load_tec_bdy, eval = FALSE}
# Test upload one, some, many to local or PROD:
x <- tec_bdy_cae[1,] %>% as.list() %>% 
  # Or use any of:
  # tfl_tae[1:100,] %>% 
  # tfl_tae[1:1000,] %>% 
  wastd_POST(serializer = "occ-community-areas")

# Upload all occurrences to TSC PROD
# LONG RUNNING UPLOAD
tec_bdy_cae %>%
  filter(grepl(fat_filter, community)) %>%
  chunk_post(serializer = "occ-community-areas")
```

### Upload TEC buffers to TSC

The TEC buffer upload excludes all but the numerous ones

```{r load_tec_buf, eval = FALSE}
# Test upload one, some, many to local or PROD:
x <- tec_buf_cae[1,] %>% as.list() %>%
  # Or use any of:
  # tfl_tae[1:100,] %>%
  # tfl_tae[1:1000,] %>%
  wastd_POST(serializer = "occ-community-areas")

tec_buf_cae %>%
 dplyr::filter(!grepl(fat_filter, community)) %>%
 chunk_post(serializer = "occ-community-areas")
```

### Upload TEC sites to TSC

```{r load_tec_site, eval = FALSE}
# Test upload one, some, many to local or PROD:
x <- tec_site_cae[1,] %>% as.list() %>% 
  # Or use any of:
  # tfl_tae[1:100,] %>% 
  # tfl_tae[1:1000,] %>% 
  wastd_POST(serializer = "occ-community-points")

# Upload all occurrences to TSC PROD
# LONG RUNNING UPLOAD
tec_site_cae %>%
  dplyr::filter(grepl(fat_filter, community)) %>%
  chunk_post(serializer = "occ-community-points")
```

### Upload ObservationGroups

```{r, eval=FALSE}
# Example: one record
tec_hab_comp[1,] %>% 
  wastdr::wastd_bulk_post("occ-observation")

# Bulk upload
# LONG RUNNING UPLOAD
tec_hab_comp %>% 
  wastdr::wastd_bulk_post("occ-observation")
```

## Conservation Documents

## Fire History

## Conservation Threats and Actions


# Migrated Data (TSC)

Data from TSC is extracted through the TSC API and transformed into a usable
format. This process is also the template for future reporting from TSC.

Expand the code block below to view the process.

## Conservation listings

```{r get_tsc_ccl2, message=FALSE, warning=FALSE}
if (file.exists(tsc_cl_community_datafile)) {
  load(tsc_cl_community_datafile)
} else {
# Taxon conservation listings for communities
  tsc_cl_communities <- "community-conservationlisting" %>% 
    wastdr::wastd_GET() %>%
    wastdr::wastd_parse() %>% 
    dplyr::mutate(com_label = community)
   
save(tsc_cl_communities, file = tsc_cl_community_datafile, compress="xz")
}
```

## Occurrences

We get Community occurrences with their point and boundary representations from 
TSC through the API endpoint
[occ-community-points](https://tsc.dbca.wa.gov.au/api/1/occ-community-points/).
[occ-community-areas](https://tsc.dbca.wa.gov.au/api/1/occ-community-areas/).

Currently, all Community occurrences are georeferenced with boundaries 
(polygons) and site visits.

Occurrences are presented as `occ` with DBCA Region and District names (where
applicable).

```{r get_tsc_occ}
if (file.exists(tsc_occ_community_datafile)) {
  load(tsc_occ_community_datafile)
} else {
tsc_cae_data <- wastdr::wastd_GET("occ-community-points") # k records

tsc_community_sites <- tsc_cae_data %>%
  magrittr::extract2("data") %>% 
  geojsonio::as.json() %>%
  geojsonsf::geojson_sf() %>% 
  dplyr::mutate(area_type = area_type %>% as.character()) %>%
  dplyr::filter(area_type == 12) 

tsc_community_boundaries <- tsc_cae_data %>%
  magrittr::extract2("features") %>%
  geojsonio::as.json() %>%
  geojsonsf::geojson_sf() %>% 
  dplyr::mutate(area_type = area_type %>% as.character()) %>% 
  dplyr::filter(area_type == 10) 

save(tsc_cae_data,
     tsc_community_sites,
     tsc_community_boundaries,
     #tsc_community_boundaries,
     file = tsc_occ_community_datafile, 
     compress="xz")
}
```

# Compare legacy to migrated data

This section provides an automated comparison between original data from TEC,
and TEC data as uploaded into TSC.

Data custodians should be able to comprehend this section, and be able to verify
that the data migration has worked correctly.

Legacy data snapshot used for TEC was updated last on `r snapshot_last_updated`.

## Summary statistics

Check unique number of communities by com\_label. Check unique number of observations
and identify observations missing from TSC compared to TEC.

```{r make_tec_summary}
tsc_ccl_communities <- tsc_ccl_communities %>% 
  dplyr::mutate(com_label = community)

tec_ccl_unique_comm <- tec_ccl$com_label %>%
  unique() %>%
  length() # 476

tsc_ccl_unique_comm <- tsc_ccl$com_label %>%
  unique() %>%
  length() # 378
```

## Conservation Listing

TEC has `r nrow(tec_ccl)` conservation listings of `r tec_ccl_unique_comm` 
communities. TSC has `r nrow(tsc_ccl)` community conservation listings of 
`r tsc_ccl_unique_comm` unique communities.

### tec\_ccl conservation listings not in tsc\_ccl

Any records in the following table indicate conservation listings in TEC that
were not migrated into TSC.

```{r show_tec_ccl_not_in_tsc}
tec_ccl %>%
  dplyr::anti_join(tsc_ccl, by = "com_label") %>%
  reactable::reactable(filterable = TRUE)
```

### tsc\_ccl conservation listings not in tec\_ccl

The following table shows any conservation listings in TSC which are not in TEC.

```{r show_tsc_ccl_not_in_tec}
tsc_ccl %>%
  dplyr::anti_join(tec_ccl, by = "com_label") %>%
  reactable::reactable(filterable = TRUE)
```

### Conservation criteria mapping

Conservation criteria were manually mapped for each community, therefore they need
to be checked to confirm whether the mapping is correct.

```{r how_cl_mapping}
tec_conscrit %>%
  reactable::reactable(filterable = TRUE)
```

In addition, some conservation criteria could not be mapped as they do not exist 
in the `list_code` / `category_code`. These need to be corrected before the 
manual mapping can be updated and the correct criteria assigned for all communities.

### Conservation listing dates

Below are the dates of the most recent conservation criteria changes made in the
snapshot of the TFA.

``` {r qa_effective_dates}
tsc_corner_dates <- tsc_ccl %>%
  summarise(
    effective_from_min = min(effective_from, na.rm = T),
    effective_from_max = max(effective_from, na.rm = T)
  )

tec_corner_dates <- tec_ccl %>%
  summarise(
    effective_from_min = min(effective_from, na.rm = T),
    effective_from_max = max(effective_from, na.rm = T)
  )

cl_corner_dates <- rbind(tec_corner_dates, tsc_corner_dates) %>%
  t() %>%
  magrittr::set_colnames(c("TEC", "TSC"))

cl_corner_dates %>% reactable::reactable()
```

### Conservation listing differences

Summary of the number of conservation listings for each list.

Discrepancies in numbers indicate the need for a closer review of category\_code
and criteria\_code in TEC.

Equality of numbers does not prove absence of equal numbers of false positives
and false negatives.

```{r make_conslist_summary}
make_tec_cl_summary <- 
  . %>% nrow() %>% as.data.frame() %>% magrittr::set_colnames("TEC")

tec_listing_cat_wapec <- tec_ccl %>%
  dplyr::filter(category_code %in% c("P1", "P2", "P3", "P4"))
tec_listing_cat_dbcarle <- tec_ccl %>%
  dplyr::filter(category_code %in% c("PD", "DD", "LR", "NE", "CR", "EN", "VU"))

tec_cl_sum_wapec <- 
  tec_listing_cat_wapec %>% make_tec_cl_summary()
tec_cl_sum_dbcarle <- 
  tec_listing_cat_dbcarle %>% make_tec_cl_summary()

make_tsc_cl_summary <- function(data, cn) {
  data %>%
    dplyr::select(category_cache) %>%
    dplyr::filter(str_detect(category_cache, cn)) %>%
    nrow() %>%
    as.data.frame() %>%
    magrittr::set_colnames("TSC")
}

tsc_listing_cat_wapec <- tsc_ccl %>%
  dplyr::filter(str_detect(category_cache, "WAPEC"))

tsc_listing_cat_dbcarle <- tsc_ccl %>%
  dplyr::filter(str_detect(category_cache, "DBCA_RLE"))

tsc_cl_sum_wapec <- tsc_ccl %>% 
  make_tsc_cl_summary("WAPEC")
tsc_cl_sum_dbcarle <- tsc_ccl %>% 
  make_tsc_cl_summary("DBCA_RLE")

tec_cons_cat_sum <- rbind(
  tec_cl_sum_wapec,
  tec_cl_sum_dbcarle
)

tsc_cons_cat_sum <- rbind(
  tsc_cl_sum_wapec,
  tsc_cl_sum_dbcarle
)

cons_cat_summary <- tec_cons_cat_sum %>%
  cbind(tsc_cons_cat_sum) %>%
  cbind(Category = c("WAPEC", "DBCA_RLE")) %>%
  dplyr::select("Category", everything())

cons_cat_summary %>% reactable::reactable()
```

The following tables show any conservation listings in TEC which are not in TSC, 
for each conservation list.

WAPEC

```{r}
#### WAPEC
tec_listing_cat_wapec %>%
  dplyr::anti_join(tsc_listing_cat_wapec, by = "com_label") %>%
  reactable::reactable(filterable = TRUE) # 106
```

DBCA_RLE

```{r}
#### DBCA_RLE
tec_listing_cat_dbcarle %>%
  dplyr::anti_join(tsc_listing_cat_dbcarle, by = "com_label") %>%
  reactable::reactable(filterable = TRUE) # 26
```

The following tables show any conservation listings in TSC which are not in TEC, 
for each conservation list.

WAPEC

```{r}
tsc_listing_cat_wapec %>%
  dplyr::anti_join(tec_listing_cat_wapec, by = "com_label") %>%
  reactable::reactable(filterable = TRUE) # 0
```

DBCA_RLE

```{r}
tsc_listing_cat_dbcarle %>%
  dplyr::anti_join(tec_listing_cat_dbcarle, by = "com_label") %>%
  reactable::reactable(filterable = TRUE) # 12
```

### tec\_ccl unmigrated conservation listings

Below are the listings from tec\_ccl that could not be assigned to either WAPEC or 
DBCA_RLE and therefore are not migrated, becasue the category\_code does not 
correlate to a list\_code. 

```{r show_tec_ccl_not_migrated}
tec_ccl %>%
  dplyr::anti_join(tec_listing_cat_wapec, by = c("com_id", "effective_from", "category_code")) %>%
  dplyr::anti_join(tec_listing_cat_dbcarle, by = c("com_id", "effective_from", "category_code")) %>%
  reactable::reactable(filterable = TRUE)
```

## Occurrences

### Date/ Location caveats

This section lists data issues which need to be fixed at the source (here, in 
legacy TEC).

Where a time is missing, we'll default to midnight (00:00). Where a date is
missing, we'll default to 1900-01-01.

While this modifies the original data, the consequences will not have a dramatic
effect on analyses for conservation management purposes:

-   A safe default of the observation time (midnight) could introduce an error
    of up to one day. Compared to the time frame considered (past 10-50 years of
    observations relative to time of calculation), this error is minuscule.
-   A safe default for missing dates (1900-01-01) will both exclude those
    observations from any recent observations (past 10-50 years), but still make
    the data available to identify the records for the purpose of backfilling a
    credible date.

Please review legacy data until the following numbers are all zero (or accept
default handling):

-   `r surveys %>% dplyr::filter(surveyed_on == "") %>% nrow()` survey records 
    lack an explicit date\time and were defaulted to midnight AWST.
-   `r site_visit %>% dplyr::filter(is.na(site_visit_date)) %>% nrow()` site
    records lack an explicit date\time and were defaulted to midnight AWST.
-   `r tec_bdy %>% dplyr::filter(BDY_ID ==  0) %>% nrow()` survey records 
    lack an explicit boundary_id so could not be migrated.
-   `r tec_occ_no_sit <- tec_site %>% dplyr::filter(S_ID == 0) %>% nrow()` site
    records lack an explicit site_id so could not be migrated.

There are `r nrow(tec_occ)` species occurrence records (encounters) in TEC. The
following columns are incomplete.

```{r show_tec_occ_missing_values}
tec_skim <- tec_occ %>% skimr::skim()

tec_skim %>%
  filter(n_missing > 0) %>%
  # select(-stat, -level, -formatted) %>%
  rt
```

### Default/ missing date/time

```{r show_tec_occ_missing datetime}
# Surveys
surveys_no_datetime <- surveys %>% 
    filter(surveyed_on == "")
surveys_no_datetime %>% rt

# Sites
site_visit_no_datetime <- site_visit %>% 
    filter(is.na(site_visit_date))
site_visit_no_datetime %>% rt
```

### Missing location ID

```{r show_missing_location_id}
# Boundaries
tec_bdy_missing_boundary_id <- tec_bdy %>% 
    dplyr::filter(BDY_ID == 0)
tec_bdy_missing_boundary_id %>% rt

# Sites
tec_occ_no_sit <- tec_site %>% 
    dplyr::filter(S_ID == 0)
tec_occ_no_sit %>% rt
```

### Missing date/time cae

```{r show_tec_occ_missing datetime}
# Surveys
tec_bdy_cae_no_encountered_on <- tec_bdy_cae_build %>%
  dplyr::filter(is.na(encountered_on))
tec_bdy_cae_no_encountered_on %>% rt

# Sites
tec_site_cae_no_encountered_on <- tec_site_cae_build %>%
  dplyr::filter(is.na(encountered_on))
tec_site_cae_no_encountered_on %>% rt
```

### Missing community ID cae

```{r show_missing_com_id}
# Survey communities
tec_bdy_cae_no_com_id <- tec_bdy_cae_build %>%
  dplyr::filter(is.na(community))
tec_bdy_cae_no_com_id %>% rt

# Site communities
tec_site_cae_no_com_id <- tec_site_cae_build %>%
  dplyr::filter(is.na(community))
tec_site_cae_no_com_id %>% rt
```

### Missing geometry cae

```{r show_missing_geometry}
# Surveys
tec_bdy_cae_no_geom <- tec_bdy_cae_build %>%
  dplyr::filter(geom == "null")
tec_bdy_cae_no_geom %>% rt

# Sites
tec_site_cae_no_point <- tec_site_cae_build %>%
  dplyr::filter(point == "null")
tec_site_cae_no_point %>% rt
```

There are `r nrow(tec_bdy_cae_no_encountered_on)` boundary records 
and `r nrow(tec_site_cae_no_encountered_on)` site records which 
lack an explicit date\time.

There are `r nrow(tec_bdy_cae_no_com_id)` boundary records and 
`r nrow(tec_site_cae_no_com_id)`  site records which
lack an explicit community ID.

There are `r nrow(tec_bdy_cae_no_geom)` boundary records and 
`r nrow(tec_site_cae_no_point)`  site records which
lack location data (e.g. geometry or point).

Any records listed here need to be fixed in the original Threatened 
Ecological Communities database.

### Occurrence mapping

Occurrence criteria were manually mapped for each variable, therefore they need
to be checked to confirm whether the mapping is correct. 

Landforms: These terms were mapped to 'umbrella' terms which generally follow the morphological types listed in McDonald et al. (1998, p13). However, some of the terms could not be mapped as they are vegetation types (e.g. FOR = Forest) and not landform types. 

McDonald, R.C., Isbell, R.F., Speight, J.G., Walker, J., and Hopkins, M.S. (1998) Australian Soil and Land Survey - Field Handbook, Second Addition. CSIRO, Canberra, Australia.

```{r show_tfl_lookup_mappings}
tec_landforms %>% rt
tec_drainage %>% rt
```

### Trust level of occurrence records

Currently, we assume that all occurrence records in the legacy databases are 
trustworthy. If this weren't the case, this analysis should exclude the 
non-trustworthy records.

### tec\_bdy\_cae occurrences not in tsc\_community\_boundaries

Any records in the following table indicate occurrences in `tec_bdy_cae` that are not 
in `tsc_community_boundaries`.

```{r show_tec_bdy_cae_missing_occurrences}
missing_occ_tsc_community_boundaries <- tec_bdy_cae %>%
  dplyr::anti_join(tsc_community_boundaries, by = "source_id")

missing_occ_tsc_community_boundaries %>% rt

missing_occ_tsc_community_boundaries_unique <- missing_occ_tsc_community_boundaries %>%
  dplyr::select(source_id) %>%
  distinct() 

missing_occ_tsc_community_boundaries_unique %>% rt 
```

There are `r nrow(missing_occ_tsc_community_boundaries)` occurrences 
missing from tec\_bdy\_cae when compared to tsc\_community\_boundaries. 
These missing occurrences come from 
`r nrow(missing_occ_tsc_community_boundaries_unique)` unique 
communities. The occurrences listed were likely not migrated because.....

The table below is a tally of mismatching occurrences by community and 
confirms the...

```{r make_tally_tfa_occ_tae}
# tfa_occ_tally <- tfa_occ %>%
#   dplyr::group_by(name_id) %>% 
#   dplyr::tally() %>%
#   dplyr::arrange(desc(n)) %>% 
#   ungroup()
# 
# tfa_tae_tally <- tfa_tae %>%
#   dplyr::group_by(taxon) %>% 
#   dplyr::tally() %>%
#   dplyr::arrange(desc(n)) %>% 
#   ungroup()
# 
# tfa_occ_tally %>%
#   dplyr::rename(tfa_occ = n) %>% 
#   left_join(tfa_tae_tally, by = c("name_id" = "taxon")) %>% 
#   dplyr::rename(tfa_tae = n) %>% 
#   filter(tfa_occ != tfa_tae) %>% rt
```

### tec\_site\_cae occurrences not in tsc\_community\_sites

Any records in the following table indicate occurrences in `tec_site_cae` that are not 
in `tsc_community_sites`.

```{r show_tec_bdy_cae_missing_occurrences}
missing_occ_tsc_community_sites <- tec_site_cae %>%
  dplyr::anti_join(tsc_community_sites, by = "source_id")

missing_occ_tsc_community_sites %>% rt

missing_occ_tsc_community_sites_unique <- missing_occ_tsc_community_sites %>%
  dplyr::select(source_id) %>%
  distinct() 

missing_occ_tsc_community_sites_unique %>% rt 
```

There are `r nrow(missing_occ_tsc_community_sites)` occurrences 
missing from tec\_site\_cae when compared to tsc\_community\_sites. 
These missing occurrences come from 
`r nrow(missing_occ_tsc_community_sites_unique)` unique 
communities. The occurrences listed were likely not migrated because.....

The table below is a tally of mismatching occurrences by community and 
confirms the...

```{r make_tally_tfa_tae_tsc}
# tfa_tae_tally <- tfa_tae %>%
#   dplyr::group_by(taxon) %>% 
#   dplyr::tally() %>%
#   dplyr::arrange(desc(n)) %>% 
#   ungroup()
# 
# tsc_occ_tally <- tsc_occ_fauna %>%
#   dplyr::group_by(taxon) %>% 
#   dplyr::tally() %>%
#   dplyr::arrange(desc(n)) %>% 
#   ungroup()
# 
# tfa_tae_tsc_tally <- tfa_tae_tally %>%
#   dplyr::rename(tfa_tae = n) %>% 
#   left_join(tsc_occ_tally,by = "taxon") %>% 
#   dplyr::rename(tsc_occ = n) %>% 
#   filter(tfa_tae != tsc_occ)
# # tfa_tae_tsc_tally %>% rt 
# # TODO cast sfc to tbl_df
```

# Upload to data catalogue

```{r upload_data_catalogue}
# This workbook
upload_file_to_ckan("7942b979-f768-4365-8303-f1b1e00b3a61", "EDA_communities.html")

# # Manual mapping of conservation criteria
# upload_file_to_ckan("e1c3119b-f44d-4244-8915-21097bd16b90",
#                     here::here("tfa_conscrit_w_tsc.csv"))

# Legacy TFA data
# d <- ckanr::package_show("threatened-and-priority-fauna-database")
# upload_to_ckan(
#   tfa_cons_listings, "Threatened Fauna Conservation Status Gazettal", d$id,
#   resource_id = "ac089664-de5a-4efa-af3c-ada0ec77ef1f"
# )
# same for other TFA legacy data, copy over from data_etl_fauna.Rmd
# Data upload
```

Create resource once-off to get a resource ID.
Also upload the compiled workbook.
Note, this process lags one compilation of this workbook, as the HTML output
is generated after the R code is run - knit a workbook twice to update the data catalogue.

```{r tec_upload, eval = FALSE}
d <- ckanr::package_show("threatened-ecological-communities-database")
# ckanr::resource_update("80009375-19e2-45d3-a1ae-068143fa03a5", "data_etl_tec.html") # HTML, not CSV
upload_to_ckan(communities, "Threatened Ecological Communities (TEC)",
  d$id,
  resource_id = "9782cc52-7be8-494a-a7da-51845c119a21"
)
upload_to_ckan(tec_occ, "TEC Occurrences",
  d$id,
  resource_id = "65f43392-a8c5-41e2-a31e-cc4135e9274e"
)
upload_to_ckan(sites, "TEC Site Points",
  d$id,
  resource_id = "bf4c2973-e549-408b-a583-013052072d6c"
)
upload_to_ckan(com_recommendations, "TEC Recommendations",
  d$id,
  resource_id = "fd96a053-523c-401d-8755-9116c55f5744"
)
upload_to_ckan(com_publications, "TEC Publications",
  d$id,
  resource_id = "fa51cd96-864a-4c43-a0e1-fc24621bb628"
)
upload_to_ckan(com_reviews, "TEC Reviews",
  d$id,
  resource_id = "7c39b584-bc4b-4234-aff7-ddf4808692ed"
)
upload_to_ckan(com_actions, "TEC Actions",
  d$id,
  resource_id = "17d3c4e2-df98-4ff6-9d4d-99ba54808bb4"
)
upload_to_ckan(com_history, "TEC History",
  d$id,
  resource_id = "479d7358-d42d-4c4b-93ee-1bac39d21024"
)
upload_to_ckan(occ_actions, "TEC Occurrence Actions",
  d$id,
  resource_id = "25894a68-11de-4a58-b521-6a9abd06ee40"
)
upload_to_ckan(occ_recommendations, "TEC Occurrence Recommendations",
  d$id,
  resource_id = "747464e4-2434-459a-b654-52861b37095c"
)
upload_to_ckan(occ_extent, "TEC Occurrence extent",
  d$id,
  resource_id = "502c74d7-32be-453f-aff6-c50aedd3deed"
)
upload_to_ckan(occ_additional_data, "TEC Occurrence additional data",
  d$id,
  resource_id = "8dd3454c-1bf0-4575-adcb-154b700c4283"
)
upload_to_ckan(occ_biol_process, "TEC Biological process",
  d$id,
  resource_id = "5805a671-576a-4077-b595-35ca96d7ca96"
)
upload_to_ckan(occ_nonbiol_process, "TEC Nonbiological process",
  d$id,
  resource_id = "a5341117-2735-4694-8cd4-e806f4c06668"
)
upload_to_ckan(fire_history, "TEC Fire history",
  d$id,
  resource_id = "e062f57e-f6aa-4403-a682-875dab2f77f6"
)
upload_to_ckan(occ_fauna, "TEC Occurrence fauna",
  d$id,
  resource_id = "a0eddc66-5fef-4252-b49f-691422a88f28"
)
upload_to_ckan(occ_species, "TEC Occurrence species",
  d$id,
  resource_id = "e94f1e35-30da-4982-b851-ceb888eb41b3"
)
upload_to_ckan(com_threats, "TEC Community threats",
  d$id,
  resource_id = "5426c45b-1dee-4547-a6e3-bec81585e52e"
)
upload_to_ckan(survey_threats, "TEC Survey threats",
  d$id,
  resource_id = "5b795656-a240-402e-92b8-edbe54b3fee8"
)
upload_to_ckan(site_visit, "TEC Site visit",
  d$id,
  resource_id = "85cef94b-d12e-4aff-bd24-446d1c0757db"
)
upload_to_ckan(voucher_specimens, "TEC Voucher specimens",
  d$id,
  resource_id = "6b8fe493-8183-4fe8-a91a-67a569bf9c46"
)
upload_to_ckan(tec_cons_listing_categories, "TEC Conservation Listing Categories",
  d$id,
  resource_id = "f0085651-8c38-496e-a6bd-1adc7ae2f06a"
)
upload_to_ckan(tec_cons_listing_criteria, "TEC Conservation Listing Criteria",
  d$id,
  resource_id = "9483f333-97fd-4975-a799-d44bf8bd252a"
)
upload_to_ckan(communities, "TEC Communities",
  d$id,
  resource_id = "3171d777-ef1a-4b1b-ac48-7807fa033ed5"
)
upload_to_ckan(com_actions, "TEC Community actions",
  d$id,
  resource_id = "1cad3694-c57f-401a-bb77-0ce0cf95f539"
)
upload_to_ckan(com_reviews, "TEC Community reviews",
  d$id,
  resource_id = "803e797b-4b49-4fc7-89cd-95a7fb895c39"
)
upload_to_ckan(conditions, "TEC Conditions",
  d$id,
  resource_id = "a8dd7571-8ee3-407d-b77e-234646a2e4fa"
)
upload_to_ckan(datum, "TEC Datum",
  d$id,
  resource_id = "35683a41-30dd-40d2-b62e-fd644c899206"
)
upload_to_ckan(endorsement, "TEC Endorsement",
  d$id,
  resource_id = "b39962c9-3fca-4024-a809-e1009f12ad44"
)
upload_to_ckan(former_range, "TEC Former range",
  d$id,
  resource_id = "af5cc256-c21b-4dc3-a795-eac07a3b8f8d"
)
upload_to_ckan(recovery_plans, "TEC Recovery plans",
  d$id,
  resource_id = "6a915a4c-fd6f-4cff-bc2a-e33e95fe9790"
)
upload_to_ckan(items, "TEC Items",
  d$id,
  resource_id = "e3aaef74-eaae-4dd4-8ddb-107d7e404272"
)
upload_to_ckan(maps, "TEC Maps",
  d$id,
  resource_id = "74c93fda-328b-40bf-a743-6be184b9226a"
)
upload_to_ckan(occ_maps, "TEC Occurrence maps",
  d$id,
  resource_id = "3350e442-cf20-4b65-a0d7-fd5ef3c4c9f9"
)
upload_to_ckan(occ_decline, "TEC Occurrence decline",
  d$id,
  resource_id = "6b470e46-7e51-4b9d-878f-c4b4d00e2a7c"
)
upload_to_ckan(range_decline, "TEC Range decline",
  d$id,
  resource_id = "79cd3f81-4d18-4644-864f-bec26ad63f43"
)
upload_to_ckan(reliability, "TEC Reliability",
  d$id,
  resource_id = "8f5f3c0c-98ef-4a04-a073-6a868967e4ea"
)
upload_to_ckan(sites, "TEC Sites",
  d$id,
  resource_id = "22a16d64-f733-4b2d-8612-f5fc61f18f73"
)
upload_to_ckan(sources, "TEC Sources",
  d$id,
  resource_id = "d194358b-582a-4ad7-8796-f26bca0e2325"
)
upload_to_ckan(species_roles, "TEC Species roles",
  d$id,
  resource_id = "9e7db52a-b6ef-492e-828a-ca99a03cabdf"
)
upload_to_ckan(status, "TEC Status",
  d$id,
  resource_id = "7ce3611e-e519-4070-aa1c-cd682e5dad64"
)
upload_to_ckan(survey_conditions, "TEC Survey conditions",
  d$id,
  resource_id = "964a2c44-9872-4ab6-8371-95d32a83a3f3"
)
upload_to_ckan(surveys, "TEC Surveys",
  d$id,
  resource_id = "e425d0b9-b4bf-4ec7-b3b9-9341dfc2aa23"
)
upload_to_ckan(impacts, "TEC Impacts",
  d$id,
  resource_id = "5762b744-0891-402a-a885-61607bf22aa6"
)
upload_to_ckan(threats, "TEC Threats",
  d$id,
  resource_id = "7e45dabf-a7ad-465e-9150-d096fdf45891"
)
```

