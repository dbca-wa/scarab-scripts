---
title: 'Data ETL: Communities'
author: "Florian Mayer and Milly Piggott, DBCA"
date: "`r Sys.time()`"
always_allow_html: yes
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    fig_width: 10
    fig_height: 6
    code_folding: hide
    theme: lumen
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = TRUE)
source("helpers.R")
```

# Context
This workbook summarises the legacy data migration and QA for the Threatened
Ecological Communities database (TEC).

<img src="https://data.dpaw.wa.gov.au/dataset/79e90d7b-33a3-4aa0-8634-8a12033eb21d/resource/98588a4e-b3af-452b-bbf4-f63ca7697752/download/tsc-progress.jpg" 
width="100%" alt="Legacy data migration and QA diagram"/>

By default, all code blocks are collapsed to provide better readability to the
non-technical audience. Feel free to expand the code blocks to view the process.

The code for all SCB workbooks is under version control at 
[github](https://github.com/dbca-wa/scarab-scripts).


# Extract and transform legacy Data from TEC
Data from the Threatened Ecological Communities Database (TEC) is downloaded from the 
[TEC dataset](https://data.dpaw.wa.gov.au/dataset/threatened-ecological-communities-database)
on the DBCA data catalogue, then extracted and transformed.

## Communities
```{r load_tec, message=FALSE}
tec <- dl_mdbzip("598b1e70-5707-4dbc-a665-1189e1524ebe")

snapshot_last_updated <- "598b1e70-5707-4dbc-a665-1189e1524ebe" %>%
  ckanr::resource_show() %>%
  magrittr::extract2("last_modified") %>%
  lubridate::as_datetime() %>%
  lubridate::with_tz("Australia/Perth")

# Cached data from TSC - delete to force refresh
datafile_tsc_comm <- here::here("data", "etl_comm_tsc.Rda")

former_range <- tec$FORMER_RANGES %>%
  dplyr::transmute(
    former_range_code = FORMER.RANGE %>% as.character(),
    former_range = FORMER.RANGE.DESC %>% as.character()
  )
# make_coldef(former_range)

range_decline <- tec$RANGE_DECLINE %>%
  dplyr::transmute(
    range_decline_id = RANGE.DECLINE %>% as.integer(),
    range_decline = RANGE.DECLINE.DESC %>% as.character()
  )
# make_coldef(range_decline)

occ_decline <- tec$OCCURRENCES_DECLINE %>%
  dplyr::transmute(
    occ_decline_id = OCC.DECLINE %>% as.integer(),
    occ_decline = OCC.DECLINE.DESC %>% as.character()
  )
# make_coldef(occ_decline)

status <- tec$STATUS %>%
  dplyr::transmute(
    status_code = STATUS.CODE %>% as.character(),
    status = STATUS.DESC %>% as.character()
  )
# status %>% make_coldef()
# unique(status$status_code) # "BELIEVED"   "IDENTIFIED" - where used?

communities <- tec$COMMUNITIES %>%
  tibble::as_tibble() %>%
  dplyr::transmute(
    com_id = COM.NO %>% as.integer(),
    com_label = COM.ID %>% as.character(),
    com_name = COM.NAME %>% as.character(),
    former_range_code = COM.FORMER.RANGE %>% as.character(),
    range_decline_id = COM.RANGE.DECLINE %>% as.integer(),
    occ_decline_id = COM.OCC.DECLINE %>% as.integer(),
    com_tec_listing = COM.TEC.LISTING %>% as.integer(),
    com_original_area = COM.ORIG.AREA %>% as.double(),
    com_area_accuracy = COM.AREA.ACC %>% as.double(),
    preliminary = COM.PRELIMINARY %>% as.character(),
    status = COM.STATUS %>% as.character()
  ) %>%
  dplyr::left_join(former_range, by = "former_range_code") %>%
  dplyr::left_join(range_decline, by = "range_decline_id") %>%
  dplyr::left_join(occ_decline, by = "occ_decline_id") %>%
  dplyr::select(-former_range_code, -range_decline_id, -occ_decline_id)

com_short <- communities %>% dplyr::select(com_id, com_label, com_name)
```

## Conservation listings
```{r load_tec_cons, message=FALSE}
tec_cons_cat <- tec$CATEGORY_TYPES %>%
  dplyr::transmute(
    category_code = CT.TYPE %>% as.character(),
    category_label = CT.DESC %>% as.character(),
    authority = CT.AUTHORITY.CODE %>% as.character()
  )

tec_cons_crit<- tec$CRITERIA_CODES %>%
  dplyr::transmute(
    criterion_code = CRIT.CODE %>% as.character(),
    criterion_description = CRIT.DESC %>% as.character()
  )
readr::write_csv(tec_cons_crit,path = here::here("data","tec_cons_crit.csv"))

# Using a built-in function to turn uppercase into lowercase? Nah. Hold my beer.
authorities <- tec$AUTHORITIES # A lookup for upper cased authorities vs lower cased authorities.
endorsement <- tec$ENDORSED_BY # another lookup for lower case.

# primary
tec_cons_listing_categories <- tec$CATEGORIES %>%
  dplyr::transmute(
    com_id = COM.NO %>% as.integer(),
    effective_from = CAT.EFFECT.DATE %>% parse_as_datetime(),
    category_code = CAT.CT.TYPE %>% as.character(),
    cat_comment = CAT.COMMENT %>% as.character(),
    cat_review_date = CAT.REVIEW.DATE %>% parse_as_datetime(),
    cat_endorsed_code = CAT.ENDORSED.CODE %>% as.character(),
    cat_endorsed_date = CAT.ENDORSED.DATE %>% parse_as_datetime(),
    cat_endorsed_by_minister = CAT.ENDORSED.BY.MINISTER %>% as.character()
  ) %>%
  dplyr::left_join(com_short, by = "com_id") %>%
  dplyr::left_join(tec_cons_cat, by = "category_code") %>% 
  tibble::rowid_to_column("source_id")

tec_cons_listing_criteria <- tec$CATEGORY_CRITERIA %>%
  dplyr::transmute(
    com_id = COM.NO %>% as.integer(),
    effective_from = CAT.EFFECT.DATE %>% parse_as_datetime(),
    criterion_code = CC.CRIT.CODE %>% as.character()
  ) %>%
  dplyr::left_join(com_short, by = "com_id") %>%
  dplyr::left_join(tec_cons_crit, by = "criterion_code")
# join com_short, criteria codes

# TODO: load cons crit from IUCN RLE into TSC, map resulting codes to:
# tec_cons_crit$criterion_code

## Check for differences between categories and criteria and then join criteria to categories for all communities
tec_cons_cat_mis_crit <- tec_cons_listing_categories %>% 
  anti_join(tec_cons_listing_criteria, by = c("com_id","effective_from")) #132

tec_cons_crit_mis_cat <- tec_cons_listing_criteria %>% 
  anti_join(tec_cons_listing_categories, by = c("com_id","effective_from")) # 0

tec_cons_listing <- tec_cons_listing_categories %>% 
  left_join(tec_cons_listing_criteria, by = c("com_id","effective_from","com_label","com_name"))

## Extract criterion_codes to manual map all criteria
all_crit_map <- tec_cons_listing %>%
  dplyr::distinct(criterion_code) 
readr::write_csv(all_crit_map, path = here::here("data","all_tec_conscrit.csv"))

```

## Occurences
```{r tec_occ}
reliability <- tec$RELIABILITY %>% dplyr::transmute(
  reliability_id = BR.CODE %>% as.character(),
  reliability = BR.DESC %>% as.character()
)
  
tec_occ <- tec$OCCURRENCES %>%
  tibble::as_tibble() %>%
  dplyr::transmute(
    # IDs
    occ_id = OCC.UNIQUE.ID %>% as.integer(),
    com_id = COM.NO %>% as.integer(),
    occ_no = OCC.NO %>% as.integer(),
    source_code = OCC.SOURCE.CODE %>% as.character(),

    # spatial references
    boundary_id = BDY.ID %>% as.integer(),
    boundary_desc = OCC.BOUNDARY.DESC %>% as.character(),
    # boundary_no = OCC.NO.BOUNDARY %>% as.integer, # empty
    buffer_radius = OCC.BUFFER.RADIUS %>% as.integer(),
    original_area = OCC.ORIGINAL.AREA %>% as.double(),
    area_accuracy = OCC.AREA.ACCURACY %>% as.double(),

    # occ details
    species_desc = OCC.SPECIES.DESC %>% as.character(),
    commonwealth_desc = OCC.COMMONWEALTH.DESC %>% as.character(),
    confidential_id = OCC.CONFIDENTIAL %>% as.integer(),
    reliability_id = OCC.BR.CODE %>% as.character(),
    desc = OCC.DESC %>% as.character(),
    status_code = OCC.STATUS.CODE %>% as.logical(),
    ctrc_sys = OCC.CTRC.SYS %>% as.integer(), # FK CTRC_SYSTEMS
    ctrc_recommendation = OCC.CTRC.RECOMMENDATION %>% as.character(),
    cwealth_listing = OCC.CWEALTH.LISTING %>% as.character(),
    data = OCC.DATA %>% as.character(),
    other = OCC.OTHER %>% as.character(),
    soil = OCC.SOIL %>% as.character(),
    surf_geology = OCC.SURF.GEOLOGY %>% as.character(),
    land_element = OCC.LAND.ELEMENT %>% as.character(),
    water = OCC.WATER %>% as.character(),
    drainage = OCC.DRAINAGE %>% as.character(),
    com_structure = OCC.COM.STRUCTURE %>% as.character(),
    classification = OCC.CLASSIFICATION %>% as.character(),
    other_attr = OCC.OTHER.ATTR %>% as.character(),

    # spatial lookups
    beard_dist_code = OCC.BEARD.DIST.CODE %>% as.character(),
    beard_map_code = OCC.BEARD.MAP.CODE %>% as.character(),
    beard_desc = OCC.BEARD.DESC %>% as.character(),
    ibra_reg_code = OCC.IBRA.REG.CODE %>% as.character(),
    dola_ref = OCC.DOLA.REF %>% as.character(),
    bush_forever_site_no = OCC.BUSH.FOREVER.SITE.NO %>% as.integer(),
    zone_code = OCC.ZONE.CODE %>% as.character(),

    # audit
    created_by = USERNAME %>% as.character(),
    created_on = OCC.DATE.ENTERED %>%
      lubridate::parse_date_time(., orders = orders, tz = tz),
    changed_on = OCC.DATE.EDITED %>%
      as.character() %>%
      lubridate::parse_date_time(., orders = orders, tz = tz)
  ) %>%
  dplyr::left_join(com_short, by = "com_id") %>%
  # dplyr::left_join(confidentiality, by = "confidential_id") %>%
  dplyr::left_join(reliability, by = "reliability_id") %>%
  dplyr::select(-confidential_id, reliability_id)
```

# Extract and transform conservation criteria Data from TSC
Conservation criteria from TSC are downloaded from the TSC API 
and transformed into a usable format for manual mapping to TEC.

A manual step annotated legacy conservation criteria exported from TEC to 
conservation criteria IDs in TSC in a spreadsheet.

``` {r extract_tsc_cons_criteria, message=FALSE}
tsc_conslists_com <- "conservationlist" %>%
  wastdr::wastd_GET(api_url = prod,
                    query = c(scope_communities = TRUE)) %>%
  magrittr::extract2("features") %>%
  {
    tibble::tibble(
      list_id = purrr::map_int(., "id"),
      list_code = purrr::map_chr(., "code"),
      label = purrr::map_chr(., "label"),
      scope_communities = purrr::map_chr(., "scope_communities"),
      scope_wa = purrr::map_chr(., "scope_wa"),
      scope_cmw = purrr::map_chr(., "scope_cmw")
    )
  }

# list_id of TSC cons lists applicable to communities
# DBCA_RLE 11
# WAPEC 12
# IUCN_RLE 16

# tsc_conscat$id = TSC ID for the cons category
# tsc_conscat$label = tec_cons_listing_categories$category_code
tsc_conscat <- "conservationcategory" %>%
  wastdr::wastd_GET(api_url = prod) %>%
  magrittr::extract2("features") %>%
  {
    tibble::tibble(
      tsc_category_id = purrr::map_int(., "id"),
      category_code = purrr::map_chr(., "code"),
      tsc_label = purrr::map_chr(., "label"),
      conservation_list = purrr::map_chr(., "conservation_list")
    )
  } %>%
  dplyr::filter(conservation_list %in% c(11, 12, 16))

tsc_cons_crit <-
  wastdr::wastd_GET("conservationcriterion", api_url = prod) %>%
  magrittr::extract2("features") %>%
  {
    tibble::tibble(
      id = purrr::map_int(., "id"),
      list_id = purrr::map_int(., "conservation_list"),
      rank = purrr::map_int(., "rank"),
      code = purrr::map_chr(., "code")
      # ,
      # label = purrr::map_chr(., "label")
    )
  } %>%
  dplyr::arrange(id, rank) %>%
  dplyr::left_join(tsc_conslists_com, by = "list_id")

# Load manual mapping of TEC cons criteria from CSV file, join to tec_cons_crit
tec_conscrit <- here::here("tec_conscrit_w_tsc.csv") %>%
  readr::read_csv(
    col_types = cols(
      category_code = col_character(),
      tsc_category_id = col_character(),
      criterion_code = col_character(),
      criteria_code = col_character(),
      assigned_as_in_tsc = col_character(),
      tsc_criteria = col_character(),
      comments_MP = col_character(),
      actions = col_character()
    )
  )

tec_ccl <- tec_cons_listing %>%
  left_join(tec_conscrit, by = c("category_code","criterion_code")) 
```

# Extract and transform occurrence lookup Data from TSC
``` {r extract_tsc_occurrence_lookup, message=FALSE}
tsc_landforms <- "lookup-landform" %>%
  wastdr::wastd_GET(api_url = prod) %>%
  wastdr::wastd_parse() %>%
  readr::write_csv(path = here::here("data", "tsc_landforms.csv"))

tsc_rocktype <- "lookup-rocktype" %>%
  wastdr::wastd_GET(api_url = prod) %>%
  wastdr::wastd_parse() %>%
  readr::write_csv(path = here::here("data", "tsc_rocktype.csv"))

tsc_soiltype <- "lookup-soiltype" %>%
  wastdr::wastd_GET(api_url = prod) %>%
  wastdr::wastd_parse() %>%
  readr::write_csv(path = here::here("data", "tsc_soiltype.csv"))

tsc_soilcolour <- "lookup-soilcolour" %>%
  wastdr::wastd_GET(api_url = prod) %>%
  wastdr::wastd_parse() %>%
  readr::write_csv(path = here::here("data", "tsc_soilcolour.csv"))

tsc_drainage <- "lookup-drainage" %>%
  wastdr::wastd_GET(api_url = prod) %>%
  wastdr::wastd_parse() %>%
  readr::write_csv(path = here::here("data", "tsc_drainage.csv"))

tsc_soilcondition <- "lookup-soilcondition" %>%
  wastdr::wastd_GET(api_url = prod) %>%
  wastdr::wastd_parse() %>%
  readr::write_csv(path = here::here("data", "tsc_soilcondition.csv"))

tsc_surveymethod <- "lookup-surveymethod" %>%
  wastdr::wastd_GET(api_url = prod) %>%
  wastdr::wastd_parse() %>%
  readr::write_csv(path = here::here("data", "tsc_surveymethod.csv"))

tsc_countmethod <- "lookup-countmethod" %>%
  wastdr::wastd_GET(api_url = prod) %>%
  wastdr::wastd_parse() %>%
  readr::write_csv(path = here::here("data", "tsc_countmethod.csv"))

tsc_countsubject <- "lookup-countsubject" %>%
  wastdr::wastd_GET(api_url = prod) %>%
  wastdr::wastd_parse() %>%
  readr::write_csv(path = here::here("data", "tsc_countsubject.csv"))

tsc_plantcondition <- "lookup-plantcondition" %>%
  wastdr::wastd_GET(api_url = prod) %>%
  wastdr::wastd_parse() %>%
  readr::write_csv(path = here::here("data", "tsc_plantcondition.csv"))

tsc_samp_dest <- "lookup-sampledestination" %>%
  wastdr::wastd_GET(api_url = prod) %>%
  wastdr::wastd_parse() %>%
  readr::write_csv(path = here::here("data", "tsc_samp_dest.csv"))

# Load manual mapping of tfl lookup criteria from CSV file, and join to relevant table

## habitat composition
tfl_landcrit <- here::here("tfl_landcrit_w_tsc.csv") %>%
  readr::read_csv(
    col_types = cols(
      landform = col_character(),
      tsc_landform = col_character(),
      tsc_criteria = col_character()
    ))

tfl_rocktype <- here::here("tfl_rocktype_w_tsc.csv") %>%
  readr::read_csv(
    col_types = cols(
      rocktype= col_character(),
      tsc_rocktype = col_character(),
      tsc_criteria = col_character()
    ))

tfl_soiltype <- here::here("tfl_soiltype_w_tsc.csv") %>%
  readr::read_csv(
    col_types = cols(
      soil_type = col_character(),
      tsc_soiltype = col_character(),
      tsc_criteria = col_character()
    ))

tfl_soilcolour <- here::here("tfl_soilcolour_w_tsc.csv") %>%
  readr::read_csv(
    col_types = cols(
      soil_colour = col_character(),
      tsc_soil_colour = col_character(),
      tsc_criteria = col_character()
    ))

tfl_drainage <- here::here("tfl_drainage_w_tsc.csv") %>%
  readr::read_csv(
    col_types = cols(
      drainage = col_character(),
      tsc_drainage = col_character(),
      tsc_criteria = col_character()
    ))

tfl_hab_comp <- hab_comp %>%
  left_join(tfl_landcrit, by = c("landform")) %>% 
  left_join(tfl_rocktype, by = c("rock_type")) %>%
  left_join(tfl_soiltype, by = c("soil_type")) %>%
  left_join(tfl_soilcolour, by = c("soil_colour")) %>%
  left_join(tfl_drainage, by = c("drainage")) %>%
  dplyr::select(source,source_id,tsc_landforms,tsc_rock_type,loose_rock,tsc_soil_type,tsc_soil_colour,tsc_drainage) %>% 
  dplyr::rename(landform = tsc_landforms) %>% 
  dplyr::rename(rocktype = tsc_rock_type) %>% 
  dplyr::rename(soiltype = tsc_soil_type) %>% 
  dplyr::rename(soilcolour = tsc_soil_colour) %>%
  dplyr::rename(drainage = tsc_drainage) %>% glimpse


## Area assessment
tfl_survey_method <- here::here("tfl_survey_method_w_tsc.csv") %>%
  readr::read_csv(
    col_types = cols(
      survey_method = col_character(),
      tsc_survey_method = col_character(),
      tsc_criteria = col_character()
    ))

tfl_area_ass <- area_ass %>%
  left_join(tfl_survey_method, by = c("survey_method")) %>% 
dplyr::select(source,source_id,tsc_survey_method,surveyed_area,survey_duration) %>%
  dplyr::rename(survey_method = tsc_survey_method) %>% glimpse

## Habitat condition
tfl_soil_condition <- here::here("tfl_soil_condition_w_tsc.csv") %>%
  readr::read_csv(
    col_types = cols(
      soil_condition = col_character(),
      tsc_soil_condition = col_character(),
      tsc_criteria = col_character()
    ))

tfl_hab_cond <- hab_cond %>%
  left_join(tfl_soil_condition, by = c("soil_condition")) %>% 
dplyr::select(source,source_id,occurrence_condition,tsc_soil_condition) %>%
  dplyr::rename(soil_condition = tsc_soil_condition) %>% glimpse

## Plant count
tfl_plant_count_method <- here::here("tfl_plant_count_method_w_tsc.csv") %>%
  readr::read_csv(
    col_types = cols(
      plant_count_method = col_character(),
      tsc_plant_count_method = col_character(),
      tsc_criteria = col_character()
    ))

tfl_plant_count_subject <- here::here("tfl_counted_subject_w_tsc.csv") %>%
  readr::read_csv(
    col_types = cols(
      counted_subject = col_character(),
      tsc_counted_subject = col_character(),
      tsc_criteria = col_character()
    ))

tfl_plant_condition <- here::here("tfl_plant_condition_w_tsc.csv") %>%
  readr::read_csv(
    col_types = cols(
      plant_condition = col_character(),
      tsc_Plant_condition = col_character(),
      tsc_criteria = col_character()
    ))

tfl_plant_count <- plant_count %>%
  left_join(tfl_plant_count_method, by = c("plant_count_method")) %>%
  left_join(tfl_plant_count_subject, by = c("counted_subject")) %>%
  left_join(tfl_plant_condition, by = c("plant_condition")) %>%  
  dplyr::select(
    -plant_count_method,
    -counted_subject,
    -plant_condition,
    -tsc_criteria.x,
    -tsc_criteria.y,
    -tsc_criteria
  ) %>%
  dplyr::rename(plant_count_method = tsc_plant_count_method) %>% 
  dplyr::rename(counted_subject = tsc_counted_subject) %>%
  dplyr::rename(plant_condition = tsc_Plant_condition) %>% glimpse

## Physical sample
tfl_sampdest <- here::here("tfl_sample_destination_w_tsc.csv") %>%
  readr::read_csv(
    col_types = cols(
      sample_destination = col_character(),
      tsc_sample_destination = col_character(),
      tsc_criteria = col_character()
    ))

tfl_phys_sample <- phys_sample %>%
  left_join(tfl_sampdest, by = c("sample_destination")) %>%
dplyr::select(-sample_destination,-tsc_criteria) %>%
  dplyr::rename(sample_destination = tsc_sample_destination) %>% glimpse
```

# Load legacy data from TEC into TSC
In this section, the extracted and transformed data from TEC are loaded into TSC
using the TSC API. The code is collapsed; expand the code blocks to view the 
process.

## Conservation Listings
This section loads conservation listings from TEC into TSC.

```{r summarise criterion codes into one row per date}
comm_info <- tec_ccl %>%
  dplyr::select(com_id, com_label, com_name) %>%
  distinct()

tec_cat_code <- tec_ccl %>%
  dplyr::group_by(com_id, effective_from, tsc_category_id) %>%
  dplyr::arrange (category_code) %>%
  dplyr::summarise(category_code = paste(category_code, collapse = ","))

tec_crit_code <- tec_ccl %>%
  dplyr::group_by(com_id, effective_from) %>%
  dplyr::arrange (criteria_code) %>%
  dplyr::summarise(criteria_code = paste(criteria_code, collapse = ","))

tsc_crit_code <- tec_ccl %>%
  dplyr::group_by(com_id, effective_from) %>%
  dplyr::arrange (tsc_criteria) %>%
  dplyr::summarise(tsc_criteria = paste(tsc_criteria, collapse = ",")) %>%
  dplyr::mutate(tsc_criteria = purrr::map(tsc_criteria, chr2int))

tec_tsc <- tec_cons_listing_categories %>% 
  dplyr::left_join(tec_cat_code, by = c("com_id","effective_from","category_code")) %>% 
  dplyr::left_join(tec_crit_code, by = c("com_id","effective_from")) %>%
  dplyr::left_join(tsc_crit_code, by = c("com_id","effective_from")) 

tec_cl_tsc <- tec_tsc %>%
  dplyr::transmute(
    source = 3, # TaxonGaz.source TFA 1, TFL 2, TEC 3
    source_id = source_id %>% as.character(),
    scope = 0, # state 0, cwth 1, intl 2, ap 3
    status = 80,
    effective_from = effective_from,
    # effective_to = date_delisted,
    review_due = cat_review_date,
    community = com_label,
    category = tsc_category_id %>% as.list(),
    criteria = tsc_criteria
  ) %>%
  dplyr::filter(!is.na(category))

# dplyr::glimpse(tec_cl_tsc)
```

```{r conslist_tsc_upload, eval=F}
tec_cl_tsc %>% 
  wastdr::wastd_POST("community-conservationlisting", api_url = prod)
```

## Occurrences
TEC refers to a single AOO as "occurrence". Occurrences may be geo-referenced as boundaries and/or
buffered boundaries (buffers) and/or through point sites within.

## Boundaries
Boundaries are named after the first site (see [site visits]) captured inside the respective boundary.

```{r tec_bdy}
tec_bdy_cae <- tibble::tibble(
    community = tec_bdy$COM_ID,
    code=tec_bdy$FIRST_S_ID %||% tec_bdy$BDY_ID,
    name=tec_bdy$FIRST_S_ID %||% tec_bdy$BDY_ID,
    description = ifelse(
        is.na(tec_bdy$FIRST_S_ID),
        glue::glue("Boundary ID {tec_bdy$BDY_ID} named ",
                   "{tec_bdy$BDY_ID} for lack of sites within."),
        glue::glue("Boundary ID {tec_bdy$BDY_ID} named ",
                   "{tec_bdy$FIRST_S_ID} after first site observed within.")
    ),
    area_type = 10, # 10 bound, 11 buffer, 12 site point
    source = 13, # TEC bdy
    source_id = tec_bdy$OCC_UNIQUE,
    encountered_on=default_date,
    encountered_by=1,
    geom = tec_bdy$geometry %>% 
        sf::st_convex_hull(.) %>% 
        sf::st_buffer(., 0.00001) %>% 
        geojsonsf::sfc_geojson(.) 
    )
```

Some boundaries were digitised from a polygonised raster remote sensing product. This results in
a spray of numerous polygons, most of which were never visited in person.

Name and shame: 

```{r tec_cae_large}
numerous_communities <- tec_bdy_cae %>% 
  dplyr::group_by(community) %>% 
  dplyr::tally() %>% 
  dplyr::arrange(-n) %>% 
  filter(n>400) 

numerous_communities

fat_filter <- numerous_communities %>% 
  extract2("community") %>% 
  paste0(collapse = "|")
```

Import excluding the heavyweight communities with more than 400 features:
```{r tec_bdy_tsc, eval=F}
tec_bdy_cae %>% 
    filter(!grepl(fat_filter, community)) %>%
    chunk_post(serializer = "occ-community-areas", api_url = prod, verbose = T)
```

### Buffers

```{r tec_buf}
tec_buf_cae <- tibble::tibble(
    community = tec_buf$COM_ID,
    code=tec_buf$FIRST_S_ID %||% tec_buf$BDY_ID,
    name=tec_buf$FIRST_S_ID %||% tec_buf$BDY_ID,
    description = ifelse(
        is.na(tec_buf$FIRST_S_ID),
        glue::glue("Buffered Boundary ID {tec_buf$BDY_ID} named",
                   " {tec_buf$BDY_ID} for lack of sites within."),
        glue::glue("Buffered Boundary ID {tec_buf$BDY_ID} named",
                   " {tec_buf$FIRST_S_ID} after first site observed within.")
    ),
    area_type = 11, # 10 bound, 11 buffer, 12 site point
    source = 14, # TEC buf
    source_id = tec_buf$OCC_UNIQUE,
    encountered_on=default_date,
    encountered_by=1,
    geom = tec_buf$geometry %>% 
        sf::st_convex_hull(.) %>% 
        sf::st_buffer(., 0.00001) %>% 
        geojsonsf::sfc_geojson(.) 
    )
```

Import all but the numerous ones:

```{r tec_buf_tsc, eval=F}
tec_buf_cae %>% 
    dplyr::filter(!grepl(fat_filter, community)) %>%
    chunk_post(serializer = "occ-community-areas", api_url = prod, verbose = T)
```

### Sites

```{r tec_sit}
tec_sit_cae <- tibble::tibble(
    community = tec_sit$COM_ID,
    code=tec_sit$S_ID,
    name=tec_sit$S_ID,
    description = glue::glue("Site ID {tec_sit$S_ID} inside TEC Boundary {tec_sit$BDY_ID}"),
    area_type = 12, # 10 bound, 11 buffer, 12 site point
    source = 15, # TEC sit
    source_id = tec_sit$S_ID,
    encountered_on=default_date,
    encountered_by=1,
    point = tec_sit$geometry %>% geojsonsf::sfc_geojson(.) 
    )
```


```{r tec_sit_tsc, eval=F}
# 7008 sites
tec_sit_cae %>% 
    dplyr::filter(!grepl(fat_filter, community)) %>%
    chunk_post(serializer = "occ-community-points", api_url = prod, verbose = T)

# 17954 sites
tec_sit_cae %>% 
  dplyr::filter(community == "Banksia Woodlands of the Swan Coastal Plain") %>% 
  chunk_post(serializer = "occ-community-points", api_url = prod, verbose = T)
```


### Long running data import
This will run for about a day.
```{r tec_import_long, eval=F}
tec_sit_cae %>%
    dplyr::filter(grepl(fat_filter, community)) %>%
    chunk_post(serializer = "occ-community-points", api_url = prod, verbose = T)

tec_buf_cae %>% 
    dplyr::filter(grepl(fat_filter, community)) %>%
    chunk_post(serializer = "occ-community-areas", api_url = prod, verbose = T)

# 116538 polys from three big one
tec_bdy_cae %>% 
    filter(grepl(fat_filter, community)) %>%
    chunk_post(serializer = "occ-community-areas", api_url = prod, verbose = T)
```

## Conservation Documents

## Fire History

## Conservation Threats and Actions


# Extract and transform migrated Data from TSC
Data from TSC is extracted through the TSC API and transformed into a useable
format.

Expand the code block below to view the process.

```{r load_tsc, message=FALSE,warning=FALSE}
# TSC communities
# tsc_comm <- "community" %>%
#   wastdr::wastd_GET(
#     api_url = prod
#   ) %>%
#   wastdr::wastd_parse() 

tsc_ccl <- wastdr::wastd_GET("community-conservationlisting") %>%
  wastdr::parse_community_conservationlisting()


# tsc_ccl_comm <- tsc_ccl %>%
#   dplyr::inner_join(tsc_comm, by = "count")
```

```{r save_point, message=FALSE}
datafile <- here::here("data", "community.Rda")
if (file.exists(datafile)) {
  load(datafile)
} else {
  save(
    tsc_ccl, # TSC taxon conservation listings 
    
    file = datafile
  )
}

```


# Compare legacy from TEC to migrated data from TSC
This section provides an automated comparison between original data from TEC 
and TEC data as uploaded into TSC. 

Data custodians should be able to comprehend this section, and be able to verify 
that the data migration has worked correctly.

Legacy data snapshot used for TFA was updated last on `r snapshot_last_updated`.

## Summary statistics

```{r tfa_summary}
#
# General note: variable names should now be recycled like tec_data
#
tsc_ccl <- tsc_ccl %>% dplyr::mutate(com_label = community)
tec_ccl_unique_comm <- tec_ccl$com_label %>% unique() %>% length() # 476
tsc_ccl_unique_comm <- tsc_ccl$com_label %>% unique() %>% length() #378
```

## Conservation Listing

TEC has `r nrow(tec_ccl)` conservation listings of `r tec_ccl_unique_comm` communities.
TSC has `r nrow(tsc_ccl)` conservation listings of `r tsc_ccl_unique_comm` communities.


### TEC conservation listings not in TSC

Any records in the following table indicate community conservation listings in TEC that
were not migrated into TSC because they have not been assigned a conservation 'Category'.

```{r missing_observations}
tec_ccl %>%
  dplyr::anti_join(tsc_ccl, by = "com_label") %>%
  reactable::reactable(filterable = TRUE)
```

### TSC conservation listings not in TEC

The following table shows any conservation listings in TSC which are not in TEC.

```{r}
tsc_ccl %>%
  dplyr::anti_join(tec_ccl, by = "com_label") %>%
  reactable::reactable(filterable = TRUE)
```


### Conservation criteria mapping

Conservation criteria were manually mapped for each species, 
therefore they need to be checked to confirm whether the mapping is correct. 
```{r}
tec_conscrit %>%
  reactable::reactable(filterable = TRUE)
```

In addition, some conservation criteria could not be mapped as they do not exist 
in the list/category_code. 
These need to be corrected before the manual mapping can be updated and the 
correct criteria assigned for all communities.

### Conservation listing dates

Below are the dates of the most recent conservation criteria changes made in the
snapshot of the TFA.

Excluded are TFA cons listings of unmigrated lists (AP, RL, BCA).

``` {r effective_dates}
tsc_corner_dates <- tsc_ccl %>%
  summarise(
    effective_from_min = min(effective_from, na.rm = T),
    effective_from_max = max(effective_from, na.rm = T),
    # effective_to_min = min(effective_to, na.rm = T),
    # effective_to_max = max(effective_to, na.rm = T),
    # last_reviewed_on_min = min(last_reviewed_on, na.rm = T),
    # last_reviewed_on_max = max(last_reviewed_on, na.rm = T)
  )

tec_corner_dates <- tec_ccl %>%
  summarise(
    effective_from_min = min(effective_from, na.rm = T),
    effective_from_max = max(effective_from, na.rm = T),
    # effective_to_min = min(delisted_on, na.rm = T),
    # effective_to_max = max(delisted_on, na.rm = T),
    # last_reviewed_on_min = min(last_reviewed_on, na.rm = T),
    # last_reviewed_on_max = max(last_reviewed_on, na.rm = T)
  )

cl_corner_dates <- rbind(tec_corner_dates, tsc_corner_dates) %>%
  t() %>%
  magrittr::set_colnames(c("TEC", "TSC"))

cl_corner_dates %>% reactable::reactable()
```


### Conservation listing differences

Summary of the number of conservation listings for each list.

Discrepancies in numbers indicate the need for a closer review.

Equality of numbers does not prove absence of equal numbers of false positives
and false negatives.

```{r summary_conservation_list}
make_tec_cl_summary <- . %>% nrow() %>% as.data.frame() %>% magrittr::set_colnames("TEC")

tec_listing_cat_wapec <- tec_ccl %>% 
  dplyr::filter(category_code %in% c("P1","P2","P3","P4")) 
tec_listing_cat_dbcarle <- tec_ccl %>%
  dplyr::filter(category_code %in% c("PD","DD","LR","NE","CR","EN","VU"))

tec_cl_sum_wapec <- tec_listing_cat_wapec %>% make_tec_cl_summary
tec_cl_sum_dbcarle <- tec_listing_cat_dbcarle %>% make_tec_cl_summary

make_tsc_cl_summary <- function(data, cn){
  data %>%
  dplyr::select(category_cache) %>%
  dplyr::filter(str_detect(category_cache, cn)) %>%
  nrow() %>% 
  as.data.frame %>% 
  magrittr::set_colnames("TSC")
}

tsc_listing_cat_wapec <- tsc_ccl %>% 
  dplyr::filter(str_detect(category_cache,"WAPEC"))

tsc_listing_cat_dbcarle <- tsc_ccl %>% 
  dplyr::filter(str_detect(category_cache,"DBCA_RLE"))

tsc_cl_sum_wapec <- tsc_ccl %>% make_tsc_cl_summary("WAPEC")
tsc_cl_sum_dbcarle <- tsc_ccl %>% make_tsc_cl_summary("DBCA_RLE")

tec_cons_cat_sum <- rbind(
  tec_cl_sum_wapec, 
  tec_cl_sum_dbcarle
)

tsc_cons_cat_sum <- rbind(
  tsc_cl_sum_wapec, 
  tsc_cl_sum_dbcarle
  )

cons_cat_summary <- tec_cons_cat_sum %>%
  cbind(tsc_cons_cat_sum) %>%
  cbind(Category = c("WAPEC", "DBCA_RLE")) %>%
  dplyr::select("Category", everything())

cons_cat_summary %>% reactable::reactable()
```

The following tables show any conservation listings in TFA which are not in TSC, for each conservation list.

WAPEC
```{r}
#### WAPEC
tec_listing_cat_wapec %>% 
  dplyr::anti_join(tsc_listing_cat_wapec, by = "com_label") %>% 
  reactable::reactable(filterable = TRUE) #106
```

DBCA_RLE
```{r}
#### DBCA_RLE
tec_listing_cat_dbcarle %>% 
  dplyr::anti_join(tsc_listing_cat_dbcarle, by = "com_label") %>% 
  reactable::reactable(filterable = TRUE) #26
```

The following tables show any conservation listings in TSC which are not in TFA, for each conservation list.

WAPEC
```{r}
tsc_listing_cat_wapec %>% 
  dplyr::anti_join(tec_listing_cat_wapec, by = "com_label") %>% 
  reactable::reactable(filterable = TRUE) #0
```

DBCA_RLE
```{r}
tsc_listing_cat_dbcarle %>% 
  dplyr::anti_join(tec_listing_cat_dbcarle, by = "com_label") %>% 
  reactable::reactable(filterable = TRUE) #12

```

### TEC unmigrated conservation listings

Below are the listings from TEC that could not be assigned to either WAPEC or DBCA_RLE as the category_code does not correlate to a list_code

```{r}
tec_ccl %>% 
  dplyr::anti_join(tec_listing_cat_wapec, by = c("com_id", "effective_from", "category_code")) %>% 
  dplyr::anti_join(tec_listing_cat_dbcarle, by = c("com_id", "effective_from", "category_code")) %>% 
  reactable::reactable(filterable = TRUE) #76
```

## Occurences

# Upload to data catalogue
```{r upload_data_catalogue}
# This workbook
upload_file_to_ckan("7942b979-f768-4365-8303-f1b1e00b3a61", "EDA_communities.html")

# # Manual mapping of conservation criteria
# upload_file_to_ckan("e1c3119b-f44d-4244-8915-21097bd16b90", 
#                     here::here("tfa_conscrit_w_tsc.csv"))

# Legacy TFA data
# d <- ckanr::package_show("threatened-and-priority-fauna-database")
# upload_to_ckan(
#   tfa_cons_listings, "Threatened Fauna Conservation Status Gazettal", d$id,
#   resource_id = "ac089664-de5a-4efa-af3c-ada0ec77ef1f"
# )
# same for other TFA legacy data, copy over from data_etl_fauna.Rmd
```
