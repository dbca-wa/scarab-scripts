---
title: "TSC ETL"
author: "Florian Mayer, DBCA"
date: "`r Sys.time()`"
always_allow_html: yes
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
library(lubridate)
library(magrittr)
library(tidyverse)
library(skimr)
library(leaflet)
library(Hmisc)
library(ckanr)
library(readr)
library(wastdr)
library(dplyr)
source("helpers.R")
if (file.exists("~/.Rprofile")) source("~/.Rprofile")
ckanr::ckanr_setup(url = Sys.getenv("CKAN_URL"), key = Sys.getenv("CKAN_API_KEY"))
local_api <- "http://localhost:8220/api/1/"
uat_api <- "https://tsc-uat.dbca.wa.gov.au/api/1/"
```

# Context

* WACensus, an Oracle database, is the point of truth for WA taxonomic names at DBCA.
* KMI publishes a few WACensus views as GeoServer views.
* TSC maintains a copy of those WACensus views.

This workbook serves to update TSC via its API from KMI's WACensus views and legacy SCB data.

# Species names from WACensus

## Example: update one Taxon

```{r write_data_example}
hbvnames <- gs_getFeature(layer_name = "public:herbie_hbvnames_public")
namesprops <- purrr::map(hbvnames[["features"]], "properties")
namesprops[[1]]
wastd_POST(namesprops[[1]], serializer = "names", api_url = local_api)
```

## Batch upsert: Create or update all Taxa
Local TSC instance (dev):

```{r rock_and_roll_local, eval=F}
gjlocal <- function(data, ser) upsert_geojson(
    data, serializer = ser, api_url = uat_api, chunksize = 1000)
"public:herbie_hbvsupra_public" %>% gs_getFeature() %>% gjlocal("supra")
"public:herbie_hbvfamilies_public" %>% gs_getFeature() %>% gjlocal("families")
"public:herbie_hbvgenera_public" %>% gs_getFeature() %>% gjlocal("genera")
"public:herbie_hbvspecies_public" %>% gs_getFeature() %>% gjlocal("species")
"public:herbie_hbvvernaculars_public" %>% gs_getFeature() %>% gjlocal("vernaculars")
"public:herbie_hbvxrefs_public" %>% gs_getFeature() %>% gjlocal("xrefs")
"public:herbie_hbtparents_public" %>% gs_getFeature() %>% gjlocal("parents")
```

Production TSC instance. Adjust chunksize down when getting "504 gateway timeouts".

```{r rock_and_roll_production, eval=F}
"public:herbie_hbvnames_public" %>% gs_getFeature() %>% upsert_geojson(serializer = "names", chunksize=100)
"public:herbie_hbvsupra_public" %>% gs_getFeature() %>% upsert_geojson(serializer = "supra", chunksize=100)
"public:herbie_hbvgroups_public" %>% gs_getFeature() %>% upsert_geojson(serializer = "groups", chunksize=100)
"public:herbie_hbvfamilies_public" %>% gs_getFeature() %>% upsert_geojson(serializer = "families", chunksize=100)
"public:herbie_hbvgenera_public" %>% gs_getFeature() %>% upsert_geojson(serializer = "genera", chunksize=100)
"public:herbie_hbvspecies_public" %>% gs_getFeature() %>% upsert_geojson(serializer = "species", chunksize=100)
"public:herbie_hbvvernaculars_public" %>% gs_getFeature() %>% upsert_geojson(serializer = "vernaculars", chunksize=100)
"public:herbie_hbvxrefs_public" %>% gs_getFeature() %>% upsert_geojson(serializer = "xrefs", chunksize=100)
"public:herbie_hbtparents_public" %>% gs_getFeature() %>% upsert_geojson(serializer = "parents", chunksize=100)
```

# Users
Given a CSV with columns `name`, `phone`, `email` and `role`, we can update users as follows.
The source CSV is hand-built from different Excel spreadsheets from each location.

```{r update_users}
readr::read_csv("data/staff.csv") %>% wastd_POST(., serializer = "users", verbose = TRUE)
```

The username is generated from the `snake_case`'d field `name`.

# TEC names
TEC names were extracted in the TEC ETL workbook, then uploaded to the data catalogue.
This step accesses the CSV with TEC names from the data catalogue, transforms it into the target
format, then uploads it into TSC's API.

```{r tec_names}
# In steps to view intermediary outputs
# com <- "9782cc52-7be8-494a-a7da-51845c119a21" %>% load_ckan_csv
# com_taxa <- com %>%
#     transmute(
#         name_id = com_id + 1000000,
#         name = paste(com_label, com_name),
#         rank = 7,
#         parent = 39480)
# wastd_POST(com_taxa, "taxon", verbose = T)

# And in one go:
"9782cc52-7be8-494a-a7da-51845c119a21" %>%
  load_ckan_csv() %>%
  transmute(
    code = com_label,
    name = com_name,
    description = com_description
  ) %>%
  wastd_POST("community")
```

# Upload to CKAN
This step uploads this workbook back to the data catalogue.

```{r upload_ckan, eval=TRUE}
d <- ckanr::package_show("wacensus")
# r <- resource_create(package_id = d$id, name = "WACensus ETL to BioSysTT", format = "HTML", upload = "data_etl_wacensus.html")
ckanr::resource_update("2893ad10-dfbf-460d-a508-5195edfd9a89", "data_etl_wacensus.html")
```

